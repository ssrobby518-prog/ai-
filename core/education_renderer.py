"""Z5 â€” Education Rendererï¼ˆæ•™è‚²ç‰ˆè½‰è­¯å™¨ï¼‰ã€‚

æŠŠ Z4 ç”¢å‡ºçš„æ·±åº¦åˆ†æï¼ˆçµæ§‹åŒ–è³‡æ–™æˆ–ç´”æ–‡æœ¬ fallbackï¼‰è½‰è­¯æˆ
ã€Œæˆäººæ•™è‚²ç‰ˆã€å ±å‘Šï¼šæ·ºç™½ä½†ä¸å¹¼ç¨šã€æŠ€è¡“å¯ç†è§£ã€å¯ç›´æ¥è²¼åˆ° Notionã€
å¯åšæˆ PPTã€å¯åŒ¯å…¥ XMindã€‚

å…©ç¨®è¼¸å…¥æ¨¡å¼ï¼š
- æ¨¡å¼ Aï¼ˆå„ªå…ˆï¼‰ï¼šç›´æ¥å‚³å…¥ MergedResult åˆ—è¡¨ + DeepAnalysisReport + metrics dict
- æ¨¡å¼ Bï¼ˆfallbackï¼‰ï¼šè®€å– outputs/deep_analysis.md + outputs/metrics.json

è¼¸å‡ºå››ä»½æª”æ¡ˆï¼š
1. docs/reports/deep_analysis_education_version.md       ï¼ˆNotion ä¸»ç‰ˆï¼‰
2. docs/reports/deep_analysis_education_version_ppt.md   ï¼ˆPPT åˆ‡é ç‰ˆï¼‰
3. docs/reports/deep_analysis_education_version_xmind.md ï¼ˆXMind éšå±¤å¤§ç¶±ï¼‰
4. outputs/deep_analysis_education.md                     ï¼ˆpipeline è¼¸å‡ºå‰¯æœ¬ï¼‰
"""

from __future__ import annotations

import re
from datetime import datetime
from pathlib import Path
from typing import Any

from schemas.education_models import (
    TERM_METAPHORS,
    EduNewsCard,
    SystemHealthReport,
    is_invalid_item,
    translate_fail_reason,
)
from schemas.models import DeepAnalysisReport, ItemDeepDive, MergedResult
from utils.logger import get_logger

# ---------------------------------------------------------------------------
# æˆäººç‰ˆæ¯”å–»åº«ï¼ˆæ­£å¼ä½†è¦ªåˆ‡ï¼‰
# ---------------------------------------------------------------------------

_METAPHOR_BANK: dict[str, list[str]] = {
    "ç§‘æŠ€/æŠ€è¡“": [
        "é¡ä¼¼ä¼æ¥­å…§éƒ¨å°å…¥æ–° ERP ç³»çµ±â€”â€”å‰æœŸé™£ç—›æœŸé•·ï¼Œä½†ä¸€æ—¦ä¸Šç·šæ•ˆç‡é¡¯è‘—æå‡",
        "å¯ä»¥æƒ³æˆä¸€æ¬¾æ–°ä½œæ¥­ç³»çµ±çš„å¤§ç‰ˆæœ¬æ›´æ–°ï¼šåŠŸèƒ½æ›´å¤šï¼Œä½†ç›¸å®¹æ€§éœ€è¦æ™‚é–“ç£¨åˆ",
    ],
    "å‰µæ¥­/æŠ•èè³‡": [
        "å°±åƒä¸€å®¶æ–°å‰µå…¬å¸å®Œæˆ A è¼ªå‹Ÿè³‡ï¼šæ‰‹ä¸Šæœ‰äº†è³‡é‡‘ï¼Œä½†ä¹ŸèƒŒè² äº†å°æŠ•è³‡äººçš„äº¤ä»˜æ‰¿è«¾",
        "é¡æ¯”æˆä¸€ä½è‡ªç”±å·¥ä½œè€…æ‹¿åˆ°ç¬¬ä¸€ä»½ä¼æ¥­é•·ç´„â€”â€”æ”¶å…¥ç©©å®šäº†ï¼Œä½†å½ˆæ€§ä¹Ÿç¸®å°äº†",
    ],
    "äººå·¥æ™ºæ…§": [
        "å¯ä»¥é¡æ¯”ç‚ºæ›¿æ•´å€‹éƒ¨é–€è˜äº†ä¸€ä½ä¸ä¼‘æ¯çš„åŠ©ç†â€”â€”ç”¢å‡ºé‡æš´å¢ï¼Œä½†å“è³ªä»éœ€äººå·¥æŠŠé—œ",
        "å°±åƒå°å…¥è‡ªå‹•åŒ–ç”¢ç·šï¼šæ•ˆç‡æå‡ï¼Œä½†æ—¢æœ‰æµç¨‹å’ŒäººåŠ›é…ç½®éƒ½å¾—é‡æ–°è¨­è¨ˆ",
    ],
    "æ”¿ç­–/ç›£ç®¡": [
        "é¡ä¼¼æŸå€‹è¡Œæ¥­çªç„¶å¤šäº†ä¸€æ¢æ–°æ³•è¦â€”â€”ä¼æ¥­å¿…é ˆåœ¨æœŸé™å…§å®Œæˆåˆè¦èª¿æ•´",
        "å¯ä»¥æƒ³æˆç§Ÿå±‹å¸‚å ´å‡ºäº†æ–°çš„ç®¡åˆ¶æ¢ä¾‹ï¼šæˆ¿æ±ã€æˆ¿å®¢ã€ä»²ä»‹ä¸‰æ–¹éƒ½å—å½±éŸ¿",
    ],
    "æ°£å€™/èƒ½æº": [
        "å°±åƒä¸€æ£Ÿè€å¤§æ¨“è¦åšç¯€èƒ½æ”¹é€ ï¼šçŸ­æœŸèŠ±éŒ¢ï¼Œé•·æœŸçœä¸‹çš„èƒ½æºæˆæœ¬æ›´å¯è§€",
        "é¡æ¯”æˆå¾ç‡ƒæ²¹è»Šæ›æˆé›»å‹•è»Šâ€”â€”ä½¿ç”¨ç¿’æ…£è¦æ”¹ï¼Œä½†é•·æœŸç‡Ÿé‹æˆæœ¬ä¸‹é™",
    ],
    "é‡‘è/è²¡ç¶“": [
        "å°±åƒå¤®è¡Œèª¿æ•´åˆ©ç‡â€”â€”çœ‹ä¼¼åªæ˜¯ä¸€å€‹æ•¸å­—çš„è®Šå‹•ï¼Œä½†æœƒé€£é–å½±éŸ¿æˆ¿è²¸ã€æ¶ˆè²»ã€æŠ•è³‡æ±ºç­–",
        "é¡æ¯”æˆå…¬å¸å­£å ±å…¬å¸ƒå¾Œçš„è‚¡åƒ¹åæ‡‰ï¼šæ•¸å­—æœ¬èº«é‡è¦ï¼Œä½†å¸‚å ´çš„ã€Œé æœŸè½å·®ã€æ›´é—œéµ",
    ],
    "ä½µè³¼/ä¼æ¥­": [
        "å°±åƒå…©å®¶å…¬å¸åˆä½µéƒ¨é–€â€”â€”è¡¨é¢ä¸Šæ˜¯è³‡æºæ•´åˆï¼Œå¯¦éš›ä¸Šæ¶‰åŠåœ˜éšŠæ–‡åŒ–ç£¨åˆèˆ‡å®¢æˆ¶é·ç§»",
        "å¯ä»¥é¡æ¯”æˆé€£é–å“ç‰Œæ”¶è³¼ç¨ç«‹åº—å®¶ï¼šç”¢å“ç·šæ“´å¤§ï¼Œä½†åŸæœ‰å“ç‰Œå€‹æ€§å¯èƒ½è¢«ç¨€é‡‹",
    ],
    "æ¶ˆè²»é›»å­": [
        "é¡ä¼¼æ——è‰¦æ‰‹æ©Ÿç™¼è¡¨æœƒâ€”â€”ç”¢å“æœ¬èº«é‡è¦ï¼Œä½†æ›´å€¼å¾—é—œæ³¨çš„æ˜¯å®ƒå°ä¾›æ‡‰éˆèˆ‡ç«¶å“çš„é€£é–åæ‡‰",
    ],
    "éŠæˆ²/å¨›æ¨‚": [
        "å°±åƒä¸€æ¬¾éŠæˆ²å¤§æ”¹ç‰ˆæœ¬ï¼šæ ¸å¿ƒç©å®¶çš„åæ‡‰æ±ºå®šäº†å¾ŒçºŒç”¨æˆ¶ç•™å­˜ç‡",
    ],
}

_DEFAULT_METAPHORS = [
    "å¯ä»¥æƒ³æˆä¸€é …æ–°æ”¿ç­–æˆ–æ–°ç”¢å“çš„ç™¼å¸ƒâ€”â€”æœ¬èº«æœ‰ç›´æ¥å½±éŸ¿ï¼Œä½†æ›´å€¼å¾—è§€å¯Ÿçš„æ˜¯å®ƒå¼•ç™¼çš„é€£é–åæ‡‰",
    "å°±åƒå…¬å¸å…§éƒ¨ç™¼äº†ä¸€å°å…¨å“¡å…¬å‘Šâ€”â€”è¨Šæ¯æœ¬èº«ä¸é•·ï¼Œä½†å¾ŒçºŒçš„çµ„ç¹”èª¿æ•´æ‰æ˜¯é‡é»",
]

# ---------------------------------------------------------------------------
# æ¯”å–»é¸æ“‡
# ---------------------------------------------------------------------------


def _pick_metaphor(category: str, title: str, idx: int = 0) -> str:
    """ä¾åˆ†é¡ + index æŒ‘é¸æˆäººå¯æ¥å—çš„æ¯”å–»ã€‚"""
    bank = _METAPHOR_BANK.get(category, _DEFAULT_METAPHORS)
    title_lower = title.lower()
    if any(kw in title_lower for kw in ("æ”¶è³¼", "acquire", "merger", "ä½µè³¼", "ä¹°")):
        bank = _METAPHOR_BANK.get("ä½µè³¼/ä¼æ¥­", bank)
    return bank[idx % len(bank)]


# ---------------------------------------------------------------------------
# è¡“èªç™½è©±è½‰è­¯
# ---------------------------------------------------------------------------


def _translate_term(text: str) -> str:
    """æŠŠæ–‡å­—ä¸­çš„æŠ½è±¡è¡“èªåŠ ä¸Šæ‹¬è™Ÿè§£é‡‹ï¼ˆç¬¬ä¸€æ¬¡å‡ºç¾æ‰åŠ ï¼‰ã€‚"""
    result = text
    for term, explanation in TERM_METAPHORS.items():
        pattern = re.compile(re.escape(term), re.IGNORECASE)
        if pattern.search(result):
            short_exp = explanation.split("ï¼š", 1)[-1] if "ï¼š" in explanation else explanation
            result = pattern.sub(f"{term}ï¼ˆ{short_exp}ï¼‰", result, count=1)
    return result


# ---------------------------------------------------------------------------
# æ¨¡å¼ Aï¼šçµæ§‹åŒ–è¼¸å…¥ â†’ æˆäººæ•™è‚²ç‰ˆå¡ç‰‡
# ---------------------------------------------------------------------------


def _build_card_from_structured(
    result: MergedResult,
    dive: ItemDeepDive | None,
    idx: int,
) -> EduNewsCard:
    """å¾çµæ§‹åŒ–çš„ MergedResult + ItemDeepDive å»ºç«‹æˆäººæ•™è‚²ç‰ˆå¡ç‰‡ã€‚"""
    a, b = result.schema_a, result.schema_b
    body_text = a.summary_zh or ""
    title = a.title_zh or a.source_id or result.item_id

    combined_text = f"{title} {body_text}"
    if is_invalid_item(combined_text):
        return _build_invalid_card(result.item_id, body_text, a.category or "", a.source_id,
                                   dive.signal_strength if dive else 0.0, b.final_score)

    # === æ­£å¸¸æ–°èå¡ç‰‡ ===
    # äº‹å¯¦æ ¸å°
    confirmed: list[str] = []
    unverified: list[str] = []
    if dive and dive.core_facts:
        for fact in dive.core_facts[:5]:
            confirmed.append(fact)
    if not confirmed:
        if a.key_points:
            confirmed = a.key_points[:3]

    # è­‰æ“š
    evidence_lines: list[str] = []
    if dive and dive.evidence_excerpts:
        for excerpt in dive.evidence_excerpts[:4]:
            evidence_lines.append(f"åŸæ–‡ï¼šã€Œ{excerpt}ã€")
            evidence_lines.append(f"â†’ ç¹ä¸­èªªæ˜ï¼š{_explain_excerpt(excerpt)}")
    elif dive and dive.core_facts:
        for fact in dive.core_facts[:3]:
            evidence_lines.append(f"äº‹å¯¦ï¼šã€Œ{fact}ã€")

    # æŠ€è¡“/å•†æ¥­è§£è®€
    tech_interp = _build_technical_interpretation(dive, a.category, title, a.key_points)

    # äºŒéšæ•ˆæ‡‰
    derivable = dive.derivable_effects[:4] if dive and dive.derivable_effects else []
    speculative = dive.speculative_effects[:3] if dive and dive.speculative_effects else []
    obs_metrics = dive.observation_metrics[:4] if dive and dive.observation_metrics else []

    if not derivable and dive and dive.derivable_effects:
        derivable = dive.derivable_effects[:2]
    if not obs_metrics and derivable:
        obs_metrics = [f"è§€å¯Ÿ {d[:20]} çš„å¾ŒçºŒç™¼å±•" for d in derivable[:2]]

    # è¡Œå‹•å»ºè­°
    actions = _build_action_items(dive, a.category, title)

    # åª’é«”ç´ æ
    img_sugs = _build_image_suggestions(a.category, title)
    vid_sugs = _build_video_suggestions(title, a.category)
    read_sugs = _build_reading_suggestions(title, a.category)

    return EduNewsCard(
        item_id=result.item_id,
        is_valid_news=True,
        title_plain=_clean_title(title),
        what_happened=_make_what_happened(a.key_points, title),
        why_important=_make_why_important(dive, a.category, title),
        focus_action=_make_focus_action(dive, a.category),
        metaphor=_pick_metaphor(a.category or "", title, idx),
        fact_check_confirmed=confirmed,
        fact_check_unverified=unverified if unverified else ["ï¼ˆæœ¬æ¬¡è³‡æ–™ç¯„åœå…§ç„¡éœ€é¡å¤–é©—è­‰çš„é …ç›®ï¼‰"],
        evidence_lines=evidence_lines,
        technical_interpretation=tech_interp,
        derivable_effects=derivable,
        speculative_effects=speculative,
        observation_metrics=obs_metrics,
        action_items=actions[:3],
        image_suggestions=img_sugs,
        video_suggestions=vid_sugs,
        reading_suggestions=read_sugs,
        source_url=a.source_id if a.source_id.startswith("http") else "ï¼ˆç¼ºï¼‰",
        category=a.category or "ç¶œåˆè³‡è¨Š",
        signal_strength=dive.signal_strength if dive else 0.0,
        final_score=b.final_score,
        source_name=a.source_id,
    )


def _build_invalid_card(
    item_id: str, body_text: str, category: str, source_id: str,
    signal_strength: float, final_score: float,
) -> EduNewsCard:
    """å»ºç«‹ç„¡æ•ˆå…§å®¹å¡ç‰‡ã€‚"""
    return EduNewsCard(
        item_id=item_id,
        is_valid_news=False,
        invalid_reason="æ­¤é …ç›®ä¸¦éæœ‰æ•ˆæ–°èå…§å®¹ã€‚ç³»çµ±åœ¨æŠ“å–éç¨‹ä¸­ï¼Œå°‡ç¶²ç«™çš„ç³»çµ±æç¤ºï¼ˆå¦‚ç™»å…¥é é¢ã€Session éæœŸé€šçŸ¥ï¼‰èª¤åˆ¤ç‚ºæ–°èã€‚",
        title_plain="âš ï¸ éæ–°èå…§å®¹ï¼ˆç³»çµ±è¨Šæ¯ï¼‰",
        what_happened="è³‡æ–™æŠ“å–ç¨‹å¼ï¼ˆScraperï¼‰åœ¨å­˜å–ç›®æ¨™ç¶²ç«™æ™‚ï¼Œä¸¦æœªå–å¾—å¯¦éš›çš„æ–°èå…§å®¹ï¼Œè€Œæ˜¯æ“·å–åˆ°ç¶²ç«™çš„ç³»çµ±æç¤ºé é¢ã€‚",
        why_important="è¾¨è­˜ã€Œä»€éº¼ä¸æ˜¯æ–°èã€æ˜¯è³‡è¨Šç´ é¤Šçš„åŸºç¤èƒ½åŠ›ã€‚é€™é¡é›œè¨Šåœ¨è‡ªå‹•åŒ–è³‡æ–™æ”¶é›†ä¸­å¾ˆå¸¸è¦‹ï¼Œèªè­˜å®ƒæœ‰åŠ©æ–¼æ­£ç¢ºè§£è®€å ±å‘Šã€‚",
        invalid_cause="blocked / extract_low_quality â€” ç›®æ¨™ç¶²ç«™è¦æ±‚ç™»å…¥æˆ–è§¸ç™¼äº†åçˆ¬èŸ²æ©Ÿåˆ¶",
        invalid_fix="å¯èª¿æ•´æŠ“å–ç­–ç•¥ï¼ˆå¦‚æ›´æ› User-Agentã€å¢åŠ é‡è©¦é‚è¼¯ï¼‰æˆ–å°‡è©²ä¾†æºåŠ å…¥æ’é™¤æ¸…å–®",
        evidence_lines=[
            f"åŸæ–‡ç‰‡æ®µï¼šã€Œ{body_text[:120]}ã€",
            "â†’ ç¹ä¸­èªªæ˜ï¼šé€™äº›æ–‡å­—å±¬æ–¼ç¶²ç«™çš„ Session ç®¡ç†æç¤ºï¼Œä¸åŒ…å«ä»»ä½•æ–°èè³‡è¨Šã€‚",
        ],
        source_url="ï¼ˆç¼ºï¼‰",
        category=category or "ä¸é©ç”¨",
        signal_strength=signal_strength,
        final_score=final_score,
        source_name=source_id,
    )


def _clean_title(title: str) -> str:
    """æ¸…ç†æ¨™é¡Œã€‚"""
    title = re.sub(r"[\[\]ã€ã€‘ã€Œã€ã€ã€]", "", title)
    if len(title) > 60:
        title = title[:58] + "â€¦"
    return title


def _explain_excerpt(excerpt: str) -> str:
    """ç‚ºåŸæ–‡ç‰‡æ®µæä¾›ç¹ä¸­è§£é‡‹ã€‚"""
    text = excerpt.strip()
    if len(text) > 100:
        text = text[:98] + "â€¦"
    return f"æ­¤æ®µåŸæ–‡è¡¨æ˜ï¼š{text}"


def _make_what_happened(key_points: list[str], title: str) -> str:
    if key_points:
        first = key_points[0]
        if len(first) > 100:
            first = first[:98] + "â€¦"
        return first
    return f"ä¸»é¡Œæ‘˜è¦ï¼š{title[:60]}"


def _make_why_important(dive: ItemDeepDive | None, category: str, title: str) -> str:
    if dive and dive.derivable_effects:
        first = dive.derivable_effects[0]
        if len(first) > 100:
            first = first[:98] + "â€¦"
        return f"æ­¤äº‹ä»¶çš„æ½›åœ¨å½±éŸ¿ï¼š{first}"
    return f"é€™æ˜¯ {category or 'ç¶œåˆ'} é ˜åŸŸçš„é‡è¦å‹•æ…‹ï¼Œå¯èƒ½å°ç›¸é—œç”¢æ¥­æˆ–ä½¿ç”¨è€…ç”¢ç”Ÿé€£é–å½±éŸ¿ã€‚"


def _make_focus_action(dive: ItemDeepDive | None, category: str) -> str:
    if dive and dive.observation_metrics:
        return f"å»ºè­°æŒçºŒé—œæ³¨ï¼š{dive.observation_metrics[0]}"
    return f"å»ºè­°é—œæ³¨ {category or 'æ­¤é ˜åŸŸ'} å¾ŒçºŒçš„å®˜æ–¹å…¬å‘Šæˆ–å¸‚å ´å›æ‡‰ã€‚"


def _build_technical_interpretation(
    dive: ItemDeepDive | None, category: str, title: str, key_points: list[str],
) -> str:
    """å»ºç«‹ 120-220 å­—çš„æŠ€è¡“/å•†æ¥­è§£è®€ã€‚"""
    parts: list[str] = []

    if dive and dive.first_principles:
        parts.append(_translate_term(dive.first_principles[:200]))
    elif dive and dive.forces_incentives:
        parts.append(_translate_term(dive.forces_incentives[:200]))

    if dive and dive.event_breakdown:
        parts.append(_translate_term(dive.event_breakdown[:150]))

    if not parts:
        # fallbackï¼šç”¨ key_points çµ„æˆè§£è®€
        cat_label = category or "ç¶œåˆ"
        kp_text = "ï¼›".join(key_points[:3]) if key_points else title[:40]
        parts.append(
            f"æœ¬äº‹ä»¶æ¶‰åŠ {cat_label} é ˜åŸŸã€‚æ ¸å¿ƒè¦é»åŒ…æ‹¬ï¼š{kp_text}ã€‚"
            f"å¾ç”¢æ¥­éˆè§’åº¦ä¾†çœ‹ï¼Œé€™é¡äº‹ä»¶é€šå¸¸æœƒå½±éŸ¿ä¸Šä¸‹æ¸¸çš„åˆä½œé—œä¿‚èˆ‡ç«¶çˆ­æ ¼å±€ï¼Œ"
            f"å€¼å¾—æŒçºŒè¿½è¹¤å¾ŒçºŒçš„å¸‚å ´åæ‡‰èˆ‡æ”¿ç­–å›æ‡‰ã€‚"
        )

    result = " ".join(parts)
    if len(result) < 120:
        result += f" ç¶œåˆä¾†çœ‹ï¼Œæ­¤äº‹ä»¶åœ¨ {category or 'è©²é ˜åŸŸ'} å…·æœ‰æŒ‡æ¨™æ€§æ„ç¾©ï¼Œå¾ŒçºŒç™¼å±•æ–¹å‘å–æ±ºæ–¼å„æ–¹åˆ©å®³é—œä¿‚äººçš„å›æ‡‰é€Ÿåº¦èˆ‡ç­–ç•¥èª¿æ•´ã€‚"
    if len(result) > 250:
        result = result[:248] + "â€¦"
    return result


def _build_action_items(dive: ItemDeepDive | None, category: str, title: str) -> list[str]:
    """å»ºç«‹å¯åŸ·è¡Œè¡Œå‹•ï¼ˆå«å‹•ä½œ + ç”¢å‡ºç‰© + æœŸé™å»ºè­°ï¼‰ã€‚"""
    actions: list[str] = []
    if dive and dive.opportunities:
        for opp in dive.opportunities[:3]:
            clean = opp[:80] if len(opp) > 80 else opp
            actions.append(f"æœ¬é€±å…§ï¼š{clean} â†’ ç”¢å‡ºï¼šåˆæ­¥è©•ä¼°ç­†è¨˜")
    if not actions:
        title_short = title[:20]
        actions = [
            f"æœ¬é€±å…§ï¼šæœå°‹ã€Œ{title_short}ã€çš„æœ€æ–°å ±å°ï¼Œç¢ºèªäº‹ä»¶é€²å±• â†’ ç”¢å‡ºï¼šæ‘˜è¦ç­†è¨˜",
            "å…©é€±å…§ï¼šè©•ä¼°æ­¤äº‹ä»¶å°è‡ªèº«å·¥ä½œæˆ–æŠ•è³‡çš„æ½›åœ¨å½±éŸ¿ â†’ ç”¢å‡ºï¼šé¢¨éšª/æ©Ÿæœƒæ¸…å–®",
        ]
    return actions[:3]


def _build_image_suggestions(category: str, title: str) -> list[str]:
    cat_map = {
        "ç§‘æŠ€/æŠ€è¡“": "ç§‘æŠ€ç”¢æ¥­ç¤ºæ„åœ–",
        "æ°£å€™/èƒ½æº": "èƒ½æºè½‰å‹æ¦‚å¿µåœ–",
        "é‡‘è/è²¡ç¶“": "è²¡ç¶“æ•¸æ“šè¶¨å‹¢åœ–",
        "äººå·¥æ™ºæ…§": "AI æŠ€è¡“æ¦‚å¿µåœ–",
        "æ”¿ç­–/ç›£ç®¡": "æ³•è¦æ”¿ç­–æµç¨‹åœ–",
        "ä½µè³¼/ä¼æ¥­": "ä¼æ¥­ä½µè³¼é—œä¿‚åœ–",
    }
    img_type = cat_map.get(category, "ç”¢æ¥­è¶¨å‹¢ç¤ºæ„åœ–")
    title_short = title[:15]
    return [
        f"ğŸ–¼ï¸ {img_type}ï½œé—œéµå­—ï¼š{category or 'è¶¨å‹¢'} {title_short}ï½œç”¨é€”ï¼šPPT å°é¢æˆ– Notion é…åœ–",
        f"ğŸ–¼ï¸ è³‡è¨Šåœ–è¡¨ï¼ˆInfographicï¼‰ï½œé—œéµå­—ï¼š{title_short} æ•¸æ“šè¦–è¦ºåŒ–ï½œç”¨é€”ï¼šç¤¾ç¾¤åˆ†äº«",
    ]


def _build_video_suggestions(title: str, category: str) -> list[str]:
    title_short = re.sub(r"[^\w\s\u4e00-\u9fff]", "", title)[:20].strip()
    cat_short = (category or "ç§‘æŠ€").replace("/", " ")
    return [
        f"ğŸ¬ YouTube æœå°‹ï¼šã€Œ{title_short} {cat_short} åˆ†æè§£è®€ã€",
        f"ğŸ¬ YouTube æœå°‹ï¼šã€Œ{cat_short} è¶¨å‹¢ 2025 ä¸­æ–‡ã€",
    ]


def _build_reading_suggestions(title: str, category: str) -> list[str]:
    title_short = re.sub(r"[^\w\s\u4e00-\u9fff]", "", title)[:20].strip()
    return [
        f"ğŸ“ Google æœå°‹ï¼šã€Œ{title_short} ç”¢æ¥­åˆ†æã€",
        f"ğŸ“ Google æœå°‹ï¼šã€Œ{category or 'ç§‘æŠ€'} æœ€æ–°å‹•æ…‹ {datetime.now().year}ã€",
    ]


# ---------------------------------------------------------------------------
# æ¨¡å¼ Bï¼šæ–‡æœ¬ fallback è§£æ
# ---------------------------------------------------------------------------


def _parse_deep_analysis_text(text: str) -> list[dict[str, Any]]:
    """å¾ deep_analysis.md æ–‡æœ¬ç©©å¥è§£æå‡ºæ¯å‰‡æ–°èçš„åŸºæœ¬çµæ§‹ã€‚"""
    items: list[dict[str, Any]] = []
    sections = re.split(r"^### \d+\.\s*", text, flags=re.MULTILINE)

    for section in sections[1:]:
        item: dict[str, Any] = {}
        lines = section.strip().split("\n")
        if lines:
            item["item_id"] = lines[0].strip()[:30]

        core_facts: list[str] = []
        in_facts = False
        for line in lines:
            if "æ ¸å¿ƒäº‹å¯¦" in line:
                in_facts = True
                continue
            if in_facts:
                if line.startswith("- "):
                    core_facts.append(line[2:].strip())
                elif line.startswith("**") or line.startswith("####"):
                    in_facts = False
        item["core_facts"] = core_facts

        evidence: list[str] = []
        for line in lines:
            if line.startswith("> "):
                excerpt = line[2:].strip().strip('"').strip("ã€Œã€")
                if excerpt and len(excerpt) > 5:
                    evidence.append(excerpt)
        item["evidence_excerpts"] = evidence

        for line in lines:
            m = re.search(r"ä¿¡è™Ÿå¼·åº¦:\s*([\d.]+)", line)
            if m:
                item["signal_strength"] = float(m.group(1))
                break

        if item.get("item_id"):
            items.append(item)
    return items


def _parse_metrics_dict(metrics: dict[str, Any]) -> SystemHealthReport:
    return SystemHealthReport(
        success_rate=float(metrics.get("enrich_success_rate", 0)),
        p50_latency=float(metrics.get("enrich_latency_p50", 0)),
        p95_latency=float(metrics.get("enrich_latency_p95", 0)),
        entity_noise_removed=int(metrics.get("entity_noise_removed", 0)),
        total_runtime=float(metrics.get("total_runtime_seconds", 0)),
        run_id=str(metrics.get("run_id", "unknown")),
        fail_reasons=dict(metrics.get("enrich_fail_reasons", {})),
    )


def _build_card_from_parsed(parsed: dict[str, Any], idx: int) -> EduNewsCard:
    """å¾ fallback è§£æçµæœå»ºç«‹æˆäººæ•™è‚²ç‰ˆå¡ç‰‡ã€‚"""
    item_id = parsed.get("item_id", f"item_{idx}")
    core_facts = parsed.get("core_facts", [])
    evidence = parsed.get("evidence_excerpts", [])

    combined = " ".join(core_facts + evidence)
    if is_invalid_item(combined):
        return EduNewsCard(
            item_id=item_id,
            is_valid_news=False,
            invalid_reason="ç³»çµ±æç¤ºè¨Šæ¯ï¼ŒéçœŸå¯¦æ–°èå…§å®¹",
            title_plain="âš ï¸ éæ–°èå…§å®¹ï¼ˆç³»çµ±è¨Šæ¯ï¼‰",
            what_happened="è³‡æ–™æŠ“å–éç¨‹ä¸­æ“·å–åˆ°çš„ç³»çµ±æç¤ºé é¢ï¼Œä¸¦éæ–°èã€‚",
            why_important="è¾¨è­˜ç„¡æ•ˆå…§å®¹æ˜¯ä½¿ç”¨è‡ªå‹•åŒ–å·¥å…·çš„å¿…å‚™æŠ€èƒ½ã€‚",
            invalid_cause="æŠ“å–ç›®æ¨™å›å‚³éé æœŸå…§å®¹ï¼ˆç™»å…¥é é¢æˆ–éŒ¯èª¤é é¢ï¼‰",
            invalid_fix="èª¿æ•´æŠ“å–ç­–ç•¥æˆ–å°‡ä¾†æºåŠ å…¥æ’é™¤æ¸…å–®",
            evidence_lines=[f"åŸæ–‡ç‰‡æ®µï¼šã€Œ{combined[:100]}ã€", "â†’ ç¹ä¸­èªªæ˜ï¼šæ­¤ç‚ºç³»çµ±è‡ªå‹•ç”¢ç”Ÿçš„æç¤ºæ–‡å­—ã€‚"],
            source_url="ï¼ˆç¼ºï¼‰",
            signal_strength=parsed.get("signal_strength", 0.0),
        )

    title = core_facts[0] if core_facts else item_id
    evidence_lines = []
    for e in evidence[:4]:
        evidence_lines.append(f"åŸæ–‡ï¼šã€Œ{e}ã€")
        evidence_lines.append(f"â†’ ç¹ä¸­èªªæ˜ï¼šæ­¤æ®µåŸæ–‡è¡¨æ˜ï¼š{e[:60]}")

    return EduNewsCard(
        item_id=item_id,
        is_valid_news=True,
        title_plain=_clean_title(title),
        what_happened=title if len(title) <= 100 else title[:98] + "â€¦",
        why_important="æ­¤äº‹ä»¶åæ˜ äº†ç•¶å‰çš„é‡è¦ç”¢æ¥­è¶¨å‹¢ï¼Œå€¼å¾—æŒçºŒè§€å¯Ÿå¾ŒçºŒç™¼å±•ã€‚",
        focus_action="å»ºè­°è¿½è¹¤ç›¸é—œå¾ŒçºŒå ±å°èˆ‡å®˜æ–¹è²æ˜ã€‚",
        metaphor=_DEFAULT_METAPHORS[idx % len(_DEFAULT_METAPHORS)],
        fact_check_confirmed=core_facts[:3] if core_facts else ["ï¼ˆè³‡æ–™ä¸è¶³ï¼‰"],
        fact_check_unverified=["éœ€äº¤å‰æ¯”å°å…¶ä»–ä¾†æºä»¥ç¢ºèª"],
        evidence_lines=evidence_lines,
        technical_interpretation=f"æ ¹æ“šç¾æœ‰è³‡æ–™ï¼Œæ­¤äº‹ä»¶æ¶‰åŠ {title[:30]} ç›¸é—œé ˜åŸŸã€‚ç”±æ–¼åƒ…å¾æ–‡æœ¬ fallback è§£æï¼Œè§£è®€æ·±åº¦æœ‰é™ï¼Œå»ºè­°åƒè€ƒåŸå§‹åˆ†æå ±å‘Šï¼ˆoutputs/deep_analysis.mdï¼‰å–å¾—å®Œæ•´è„ˆçµ¡ã€‚",
        action_items=[
            f"æœ¬é€±å…§ï¼šæœå°‹ã€Œ{title[:15]}ã€æœ€æ–°å ±å° â†’ ç”¢å‡ºï¼šæ‘˜è¦ç­†è¨˜",
            "å…©é€±å…§ï¼šè©•ä¼°æ­¤äº‹ä»¶èˆ‡è‡ªèº«æ¥­å‹™çš„é—œè¯æ€§ â†’ ç”¢å‡ºï¼šå½±éŸ¿è©•ä¼°è¡¨",
        ],
        image_suggestions=["ğŸ–¼ï¸ æ–°èç¤ºæ„åœ–ï½œé—œéµå­—ï¼šç”¢æ¥­è¶¨å‹¢ æ–°èï½œç”¨é€”ï¼šç°¡å ±é…åœ–"],
        video_suggestions=[f"ğŸ¬ YouTube æœå°‹ï¼šã€Œ{title[:15]} åˆ†æã€"],
        reading_suggestions=[f"ğŸ“ Google æœå°‹ï¼šã€Œ{title[:15]} ç”¢æ¥­åˆ†æã€"],
        source_url="ï¼ˆç¼ºï¼‰",
        signal_strength=parsed.get("signal_strength", 0.0),
    )


# ---------------------------------------------------------------------------
# Notion ä¸»ç‰ˆæ¸²æŸ“ï¼ˆæˆäººæ•™è‚²ç‰ˆï¼‰
# ---------------------------------------------------------------------------


_FILTER_REASON_LABELS: dict[str, str] = {
    "too_old": "æ™‚é–“éèˆŠ",
    "lang_not_allowed": "èªè¨€ä¸ç¬¦",
    "keyword_mismatch": "é—œéµå­—ä¸ç¬¦",
    "body_too_short": "å…§æ–‡éçŸ­",
}


def _render_notion_md(
    cards: list[EduNewsCard],
    health: SystemHealthReport,
    report_time: str,
    total_items: int,
    metrics: dict[str, Any],
    filter_summary: dict[str, Any] | None = None,
) -> str:
    lines: list[str] = []
    valid_count = sum(1 for c in cards if c.is_valid_news)
    invalid_count = len(cards) - valid_count

    # ===== A. å°é¢å€ =====
    fail_lines_brief = []
    for reason, count in health.fail_reasons.items():
        fail_lines_brief.append(f"{translate_fail_reason(reason)}ï¼ˆ{count} æ¬¡ï¼‰")

    lines.extend([
        "# ğŸ¤– AI æ·±åº¦æƒ…å ±åˆ†æå ±å‘Š â€” æˆäººæ•™å­¸ç‰ˆ",
        "",
        "> æœ¬å ±å‘Šå°‡ã€Œåˆ†æå¸«ç‰ˆã€çš„æ·±åº¦åˆ†æçµæœï¼Œè½‰è­¯ç‚ºä¸éœ€è¦æŠ€è¡“èƒŒæ™¯å³å¯ç†è§£çš„ç‰ˆæœ¬ã€‚",
        "> é©åˆï¼šç”¢å“ç¶“ç†ã€æŠ•è³‡äººã€ç®¡ç†å±¤ã€æˆ–ä»»ä½•å°ç§‘æŠ€è¶¨å‹¢å¥½å¥‡çš„è®€è€…ã€‚",
        "",
        "## ğŸ“‹ å°é¢è³‡è¨Š",
        "",
        "| é …ç›® | å…§å®¹ |",
        "|------|------|",
        f"| å ±å‘Šæ™‚é–“ | {report_time} |",
        f"| Run ID | `{health.run_id}` |",
        f"| åˆ†æé …ç›®æ•¸ | {total_items} å‰‡ï¼ˆæœ‰æ•ˆ {valid_count}ã€ç„¡æ•ˆ {invalid_count}ï¼‰|",
        f"| å…¨æ–‡æŠ“å–æˆåŠŸç‡ï¼ˆEnrich Success Rateï¼‰ | {health.success_rate:.0f}% |",
        f"| ç¸½åŸ·è¡Œæ™‚é–“ | {health.total_runtime:.1f} ç§’ |",
        f"| ä¸»è¦å¤±æ•—åŸå›  | {'; '.join(fail_lines_brief) if fail_lines_brief else 'ç„¡'} |",
        "",
        "**ğŸ“– é–±è®€æŒ‡å—ï¼š**",
        "",
        "1. **å…ˆçœ‹**ï¼šã€Œä»Šæ—¥çµè«–ã€â€” 2 åˆ†é˜æŒæ¡å…¨è²Œ",
        "2. **å†çœ‹**ï¼šã€Œæ¯å‰‡æ–°èå¡ç‰‡ã€â€” æ·±å…¥äº†è§£æ¯å‰‡äº‹ä»¶çš„èƒŒæ™¯èˆ‡å½±éŸ¿",
        "3. **æœ€å¾Œçœ‹**ï¼šã€ŒMetrics èˆ‡é‹ç¶­å»ºè­°ã€â€” äº†è§£ç³»çµ±ç‹€æ…‹èˆ‡æ”¹å–„æ–¹å‘",
        "",
        "---",
        "",
    ])

    # ===== B. ä»Šæ—¥çµè«– =====
    valid_cards = [c for c in cards if c.is_valid_news]
    sources = set()
    topics = set()
    for c in valid_cards:
        if c.source_name:
            sources.add(c.source_name[:20])
        if c.category:
            topics.add(c.category)

    lines.extend([
        "## ğŸ“Š ä»Šæ—¥çµè«–ï¼ˆExecutive Summaryï¼‰",
        "",
        f"æœ¬æ¬¡åˆ†æå…±è™•ç† {total_items} å‰‡è³‡æ–™é …ç›®ï¼Œå…¶ä¸­ **{valid_count} å‰‡ç‚ºæœ‰æ•ˆæ–°è**"
        + (f"ã€**{invalid_count} å‰‡ç‚ºç„¡æ•ˆå…§å®¹**ï¼ˆç³»çµ±è¨Šæ¯æˆ–æŠ“å–å¤±æ•—ï¼‰" if invalid_count else "")
        + "ã€‚",
        "",
    ])

    if valid_cards:
        titles_brief = "ã€".join(c.title_plain[:15] for c in valid_cards[:3])
        lines.append(f"æœ‰æ•ˆæ–°èæ¶µè“‹çš„ä¸»é¡ŒåŒ…æ‹¬ï¼š{titles_brief}ã€‚")
    lines.append("")

    # å¯ä¿¡åº¦è©•ä¼°
    if health.success_rate >= 80:
        reliability = "æœ¬æ‰¹æ¬¡è³‡æ–™å¯ä¿¡åº¦**è‰¯å¥½**ï¼Œå¤§éƒ¨åˆ†é …ç›®æˆåŠŸå®Œæˆå…¨æ–‡æŠ½å–èˆ‡åˆ†æã€‚"
    elif health.success_rate >= 50:
        reliability = "æœ¬æ‰¹æ¬¡è³‡æ–™å¯ä¿¡åº¦**ä¸­ç­‰**ï¼Œç´„æœ‰ä¸€åŠä»¥ä¸Šé …ç›®æˆåŠŸè™•ç†ï¼Œä½†ä»æœ‰æ”¹å–„ç©ºé–“ã€‚"
    else:
        reliability = "æœ¬æ‰¹æ¬¡è³‡æ–™å¯ä¿¡åº¦**åä½**ï¼Œå¤šæ•¸é …ç›®åœ¨æŠ“å–æˆ–åˆ†æéšæ®µé­é‡å•é¡Œï¼Œå»ºè­°æª¢æŸ¥ä¾†æºèˆ‡ç¶²è·¯ç‹€æ…‹ã€‚"
    lines.extend([
        reliability,
        "",
        "| æŒ‡æ¨™ | æ•¸å€¼ |",
        "|------|------|",
        f"| æœ‰æ•ˆé …ç›® | {valid_count} å‰‡ |",
        f"| ç„¡æ•ˆé …ç›® | {invalid_count} å‰‡ |",
        f"| ä¸»è¦ä¾†æº | {', '.join(list(sources)[:3]) if sources else 'ï¼ˆæœªè¨˜éŒ„ï¼‰'} |",
        f"| ä¸»è¦ä¸»é¡Œ | {', '.join(list(topics)[:3]) if topics else 'ï¼ˆæœªåˆ†é¡ï¼‰'} |",
        "",
        "---",
        "",
    ])

    # ===== C. ç³»çµ±èªªæ˜ QA =====
    lines.extend([
        "## â“ é€™å¥—ç³»çµ±åˆ°åº•åœ¨åšä»€éº¼ï¼ˆQAï¼‰",
        "",
        "**Q1ï¼šé€™ä»½å ±å‘Šçš„è¼¸å…¥æ˜¯ä»€éº¼ï¼Ÿ**",
        "",
        "ç³»çµ±å¾å¤šå€‹ RSS ä¾†æºï¼ˆå¦‚ TechCrunchã€36krã€Hacker Newsï¼‰è‡ªå‹•æ“·å–æœ€æ–°æ–‡ç« ã€‚æ¯ç¯‡æ–‡ç« ç¶“éå…¨æ–‡æŠ“å–å¾Œï¼Œæˆç‚ºä¸€å€‹ã€Œè³‡æ–™é …ç›®ï¼ˆItemï¼‰ã€ï¼Œä¹Ÿå°±æ˜¯æœ¬å ±å‘Šçš„åˆ†æå°è±¡ã€‚",
        "",
        "**Q2ï¼šè¼¸å‡ºæ˜¯ä»€éº¼ï¼Ÿ**",
        "",
        "ç³»çµ±ç”¢å‡ºå››ç¨®æ–‡ä»¶ï¼šâ‘  `digest.md`ï¼ˆå¿«é€Ÿæ‘˜è¦ï¼‰ã€â‘¡ `deep_analysis.md`ï¼ˆåˆ†æå¸«ç‰ˆæ·±åº¦å ±å‘Šï¼‰ã€â‘¢ æœ¬ä»½æ•™è‚²ç‰ˆå ±å‘Šã€â‘£ é¸é…çš„é€šçŸ¥æ¨é€ï¼ˆSlack/é£›æ›¸/Emailï¼‰ã€‚æ¯ä»½æ–‡ä»¶æœå‹™ä¸åŒè®€è€…ã€‚",
        "",
        "**Q3ï¼šä»€éº¼æ˜¯ Pipelineï¼ˆè³‡æ–™è™•ç†ç®¡ç·šï¼‰ï¼Ÿ**",
        "",
        "Pipeline å°±åƒä¸€åº§ã€Œè³‡æ–™å·¥å» ã€çš„ç”Ÿç”¢ç·šã€‚åŸå§‹æ–°èå¾å…¥å£é€²ä¾†ï¼Œä¾åºç¶“éæ¸…æ´—ã€åˆ†é¡ã€è©•åˆ†ã€æ·±åº¦åˆ†æç­‰ç«™é»ï¼Œæœ€çµ‚ç”¢å‡ºçµæ§‹åŒ–çš„å ±å‘Šã€‚æ¯å€‹ç«™é»å°ˆè²¬ä¸€é …ä»»å‹™ï¼Œå¦‚æœæŸç«™å‡ºéŒ¯ï¼Œä¸æœƒå½±éŸ¿å…¶ä»–ç«™çš„é‹ä½œã€‚åœ¨è³‡æ–™å·¥ç¨‹é ˜åŸŸï¼Œé€™ç¨®æ¨¡å¼ç¨±ç‚º ETLï¼ˆExtract-Transform-Loadï¼‰ï¼Œæ˜¯æœ€å¸¸è¦‹çš„è‡ªå‹•åŒ–è³‡æ–™è™•ç†æ¶æ§‹ã€‚",
        "",
        "**Q4ï¼šç‚ºä»€éº¼è¦æ‰“åˆ†æ•¸ï¼Ÿåˆ†æ•¸ä»£è¡¨ä»€éº¼ï¼Ÿ**",
        "",
        "ç³»çµ±æœƒç‚ºæ¯å‰‡æ–°èè¨ˆç®—ä¸€å€‹ç¶œåˆåˆ†æ•¸ï¼ˆfinal_scoreï¼‰ï¼Œè€ƒé‡æ–°ç©æ€§ã€å¯¦ç”¨æ€§ã€ç†±åº¦ã€å¯è¡Œæ€§ç­‰ç¶­åº¦ã€‚åªæœ‰åˆ†æ•¸è¶…éé–€æª»ï¼ˆé è¨­ 7.0ï¼‰çš„é …ç›®æ‰æœƒé€²å…¥æ·±åº¦åˆ†æéšæ®µã€‚é€™å€‹æ©Ÿåˆ¶ç¨±ç‚ºã€Œå“è³ªé–€æª»ï¼ˆQuality Gateï¼‰ã€ï¼Œç›®çš„æ˜¯æŠŠæœ‰é™çš„é‹ç®—è³‡æºé›†ä¸­åœ¨æœ€æœ‰åƒ¹å€¼çš„å…§å®¹ä¸Šã€‚",
        "",
        "**Q5ï¼šç‚ºä»€éº¼æœƒå‡ºç¾ã€Œä¸æ˜¯æ–°èçš„å­—ä¸²ã€ï¼Ÿ**",
        "",
        "è‡ªå‹•åŒ–æŠ“å–æ™‚ï¼Œéƒ¨åˆ†ç¶²ç«™æœƒè¦æ±‚ç™»å…¥ã€é¡¯ç¤º Cookie é€šçŸ¥ã€æˆ–å›å‚³ Session éæœŸçš„æç¤ºé é¢ã€‚é€™äº›é é¢æœƒè¢«æŠ“å–ç¨‹å¼ç•¶æˆæ–‡ç« å…§å®¹ã€‚æœ¬å ±å‘Šä¸­ï¼Œé€™é¡é …ç›®æœƒè¢«æ¨™è¨˜ç‚ºã€Œâš ï¸ éæ–°èå…§å®¹ã€ï¼Œä¸¦æä¾›å…·é«”çš„ä¿®å¾©å»ºè­°ã€‚",
        "",
        "**Q6ï¼šæˆ‘ä»Šå¤©è¦åšçš„æœ€å°å‹•ä½œæ˜¯ä»€éº¼ï¼Ÿ**",
        "",
        "1. èŠ± 2 åˆ†é˜è®€å®Œã€Œä»Šæ—¥çµè«–ã€",
        "2. æŒ‘ 1 å‰‡ä½ æœ€æ„Ÿèˆˆè¶£çš„æ–°èå¡ç‰‡ä»”ç´°é–±è®€",
        "3. æŒ‰ç…§å¡ç‰‡ä¸­çš„ã€Œå¯åŸ·è¡Œè¡Œå‹•ã€å®Œæˆ 1 å€‹ä»»å‹™",
        "",
        "---",
        "",
    ])

    # ===== D. ç³»çµ±æµç¨‹åœ– =====
    lines.extend([
        "## ğŸ—ºï¸ ç³»çµ±æµç¨‹åœ–",
        "",
        "```mermaid",
        "flowchart LR",
        "    A[ğŸ“¡ RSS ä¾†æº] --> B[Z1 è³‡æ–™æ“·å–]",
        "    B --> C[å»é‡è¤‡ & éæ¿¾]",
        "    C --> D[Z2 AI åˆ†ææ ¸å¿ƒ]",
        "    D --> E[Z3 å„²å­˜ & åŸºç¤å ±å‘Š]",
        "    E --> F[Z4 æ·±åº¦åˆ†æ]",
        "    F --> G[Z5 æ•™è‚²ç‰ˆè½‰è­¯]",
        "    G --> H[ğŸ“¤ è¼¸å‡º & é€šçŸ¥]",
        "```",
        "",
        "**å„ç«™èªªæ˜ï¼š**",
        "",
        "- **Z1 è³‡æ–™æ“·å–ï¼ˆIngestionï¼‰**ï¼šå¾ RSS ä¾†æºæŠ“å–æ–‡ç« ï¼Œé€²è¡Œå…¨æ–‡æ“·å–èˆ‡åŸºæœ¬æ¸…æ´—ã€‚ç™½è©±èªªï¼šã€ŒæŠŠç¶²è·¯ä¸Šçš„åŸå§‹æ–°èæŠ“ä¸‹ä¾†ã€ã€‚",
        "- **Z2 AI åˆ†ææ ¸å¿ƒï¼ˆAI Coreï¼‰**ï¼šå°æ¯å‰‡æ–°èåšæ‘˜è¦ã€åˆ†é¡ã€è©•åˆ†ã€å¯¦é«”æŠ½å–ã€‚ç™½è©±èªªï¼šã€Œè®“ AI è®€å®Œæ¯ç¯‡æ–‡ç« ä¸¦å¯«é‡é»ã€ã€‚",
        "- **Z3 å„²å­˜èˆ‡äº¤ä»˜ï¼ˆStorage & Deliveryï¼‰**ï¼šå°‡çµæœå­˜å…¥è³‡æ–™åº«ï¼Œç”Ÿæˆæ‘˜è¦å ±å‘Šã€‚ç™½è©±èªªï¼šã€ŒæŠŠæˆç¸¾è¨˜éŒ„ä¸‹ä¾†ä¸¦å¯„å‡ºæˆç¸¾å–®ã€ã€‚",
        "- **Z4 æ·±åº¦åˆ†æï¼ˆDeep Analyzerï¼‰**ï¼šå°é€šéå“è³ªé–€æª»çš„é …ç›®åšä¸ƒç¶­æ·±åº¦åˆ†æã€‚ç™½è©±èªªï¼šã€Œå°å„ªç§€çš„æ–‡ç« åšé€²éšç ”ç©¶å ±å‘Šã€ã€‚",
        "- **Z5 æ•™è‚²ç‰ˆè½‰è­¯ï¼ˆEducation Rendererï¼‰**ï¼šå°±æ˜¯ç”¢å‡ºæœ¬å ±å‘Šçš„ç’°ç¯€ï¼ŒæŠŠæŠ€è¡“èªè¨€è½‰æˆæ˜“æ‡‚ç‰ˆæœ¬ã€‚ç™½è©±èªªï¼šã€ŒæŠŠç ”ç©¶å ±å‘Šç¿»è­¯æˆç™½è©±æ–‡ã€ã€‚",
        "",
        "---",
        "",
    ])

    # ===== E. ä»Šæ—¥æ–°èå¡ç‰‡ =====
    lines.extend([
        "## ğŸ“° ä»Šæ—¥æ–°èå¡ç‰‡",
        "",
    ])

    if not cards and filter_summary:
        # Render empty-report section with filter breakdown
        input_count = filter_summary.get("input_count", 0)
        reasons = filter_summary.get("dropped_by_reason", {})
        lines.extend([
            "## ğŸ“­ æœ¬æ¬¡ç„¡æœ‰æ•ˆæ–°è",
            "",
            f"æœ¬æ¬¡ pipeline å…±æ“·å– {input_count} å‰‡åŸå§‹é …ç›®ï¼Œä½†å…¨æ•¸æœªé€šéç¯©é¸ã€‚",
            "",
            "| ç¯©é¸åŸå›  | è¢«åˆ·æ‰æ•¸é‡ |",
            "|----------|-----------|",
        ])
        for reason_key, count in reasons.items():
            label = _FILTER_REASON_LABELS.get(reason_key, reason_key)
            lines.append(f"| {label} | {count} |")
        if not reasons:
            lines.append("| ï¼ˆç„¡è©³ç´°åŸå› ï¼‰ | 0 |")
        lines.extend([
            "",
            '> ğŸ’¡ è‹¥è¦ä»¥è¼ƒå¯¬é¬†é–€æª»é‡è·‘ï¼Œè«‹ä½¿ç”¨ï¼š`$env:RUN_PROFILE="calibration"; python scripts/run_once.py`',
            "",
            "---",
            "",
        ])

    for i, card in enumerate(cards, 1):
        if not card.is_valid_news:
            lines.extend(_render_invalid_card_adult(card, i))
        else:
            lines.extend(_render_valid_card_adult(card, i))
        lines.extend(["", "---", ""])

    # ===== F. Metrics èˆ‡é‹ç¶­ =====
    lines.extend(_render_metrics_section(health, metrics))

    lines.extend([
        "",
        "---",
        "",
        "*æœ¬å ±å‘Šç”± AI Intel Education Renderer (Z5) è‡ªå‹•ç”Ÿæˆï½œæ·±åº¦ç­‰ç´šï¼šadult*",
        "",
    ])

    return "\n".join(lines)


def _render_valid_card_adult(card: EduNewsCard, idx: int) -> list[str]:
    """æ¸²æŸ“ä¸€å¼µæœ‰æ•ˆæ–°èçš„æˆäººç‰ˆå¡ç‰‡ã€‚"""
    lines = [
        f"### ç¬¬ {idx} å‰‡ï¼š{card.title_plain}",
        "",
        "#### æ‘˜è¦",
        "",
        f"- **ç™¼ç”Ÿäº†ä»€éº¼ï¼š** {card.what_happened}",
        f"- **ç‚ºä»€éº¼é‡è¦ï¼š** {card.why_important}",
        f"- **ä½ è¦é—œæ³¨ä»€éº¼ï¼š** {card.focus_action}",
        "",
    ]

    # äº‹å¯¦æ ¸å°
    lines.append("#### äº‹å¯¦æ ¸å°ï¼ˆFact Checkï¼‰")
    lines.append("")
    if card.fact_check_confirmed:
        for fact in card.fact_check_confirmed:
            lines.append(f"- âœ… {fact}")
    if card.fact_check_unverified:
        for item in card.fact_check_unverified:
            lines.append(f"- âš ï¸ {item}")
    lines.append("")

    # è­‰æ“š
    lines.append("#### è­‰æ“šç‰‡æ®µï¼ˆEvidence Snippetsï¼‰")
    lines.append("")
    if card.evidence_lines:
        for ev in card.evidence_lines:
            lines.append(f"- {ev}")
    else:
        lines.append("- ï¼ˆæœ¬å‰‡ç„¡å¯å¼•ç”¨çš„åŸæ–‡ç‰‡æ®µï¼‰")
    lines.append("")

    # æŠ€è¡“/å•†æ¥­è§£è®€
    lines.append("#### æŠ€è¡“/å•†æ¥­è§£è®€")
    lines.append("")
    lines.append(card.technical_interpretation if card.technical_interpretation else "ï¼ˆè³‡æ–™ä¸è¶³ï¼Œç„¡æ³•æä¾›æ·±åº¦è§£è®€ï¼‰")
    lines.append("")
    if card.metaphor:
        lines.append(f"> ğŸ’¡ **é¡æ¯”ç†è§£ï¼š** {card.metaphor}")
        lines.append("")

    # äºŒéšæ•ˆæ‡‰
    lines.append("#### äºŒéšæ•ˆæ‡‰ï¼ˆSecond-order Effectsï¼‰")
    lines.append("")
    lines.append("| é¡å‹ | å½±éŸ¿ | è§€å¯ŸæŒ‡æ¨™ |")
    lines.append("|------|------|----------|")
    for i, eff in enumerate(card.derivable_effects):
        obs = card.observation_metrics[i] if i < len(card.observation_metrics) else "å¾…å®š"
        lines.append(f"| ç›´æ¥å½±éŸ¿ | {eff} | {obs} |")
    for eff in card.speculative_effects:
        lines.append(f"| é–“æ¥å½±éŸ¿ï¼ˆéœ€è§€å¯Ÿï¼‰ | {eff} | æŒçºŒè¿½è¹¤ç›¸é—œå ±å° |")
    if not card.derivable_effects and not card.speculative_effects:
        lines.append("| â€” | ï¼ˆè³‡æ–™ä¸è¶³ï¼‰ | â€” |")
    lines.append("")

    # å¯åŸ·è¡Œè¡Œå‹•
    lines.append("#### å¯åŸ·è¡Œè¡Œå‹•ï¼ˆActionsï¼‰")
    lines.append("")
    for act in card.action_items:
        lines.append(f"- {act}")
    lines.append("")

    # åª’é«”ç´ æ
    lines.append("#### åª’é«”èˆ‡å»¶ä¼¸è³‡æº")
    lines.append("")
    for img in card.image_suggestions:
        lines.append(f"- {img}")
    for vid in card.video_suggestions:
        lines.append(f"- {vid}")
    for rd in card.reading_suggestions:
        lines.append(f"- {rd}")
    lines.append(f"- ğŸ”— **åŸå§‹é€£çµï¼š** {card.source_url}")

    return lines


def _render_invalid_card_adult(card: EduNewsCard, idx: int) -> list[str]:
    """æ¸²æŸ“ä¸€å¼µç„¡æ•ˆå…§å®¹çš„æˆäººç‰ˆå¡ç‰‡ã€‚"""
    lines = [
        f"### ç¬¬ {idx} å‰‡ï¼šâš ï¸ ç„¡æ•ˆå…§å®¹",
        "",
        "> **åˆ¤å®šï¼šæ­¤é …ç›®ç‚ºç„¡æ•ˆå…§å®¹ï¼Œä¸¦éçœŸå¯¦æ–°èã€‚**",
        "",
        f"**èªªæ˜ï¼š** {card.invalid_reason}",
        "",
        f"**å¯èƒ½åŸå› ï¼š** {card.invalid_cause if card.invalid_cause else 'æŠ“å–ç›®æ¨™å›å‚³éé æœŸå…§å®¹ï¼ˆå¦‚ç™»å…¥é é¢ã€404 éŒ¯èª¤ï¼‰'}",
        "",
        f"**ä¿®å¾©å»ºè­°ï¼š** {card.invalid_fix if card.invalid_fix else 'èª¿æ•´æŠ“å–ç­–ç•¥æˆ–å°‡æ­¤ä¾†æºåŠ å…¥æ’é™¤æ¸…å–®'}",
        "",
    ]
    if card.evidence_lines:
        lines.append("**åŸæ–‡ç‰‡æ®µï¼š**")
        lines.append("")
        for ev in card.evidence_lines:
            lines.append(f"- {ev}")
        lines.append("")
    return lines


def _render_metrics_section(health: SystemHealthReport, metrics: dict[str, Any]) -> list[str]:
    """æ¸²æŸ“ Metrics èˆ‡é‹ç¶­å€å¡Šã€‚"""
    lines = [
        "## ğŸ“Š Metrics èˆ‡é‹ç¶­å»ºè­°",
        "",
        "### å¥åº·åº¦å„€è¡¨æ¿",
        "",
        "| æŒ‡æ¨™ | æ•¸å€¼ | è§£è®€ | å»ºè­°é–€æª» |",
        "|------|------|------|----------|",
    ]

    # æˆåŠŸç‡
    rate = health.success_rate
    if rate >= 80:
        interp = "è‰¯å¥½ï¼šå¤§éƒ¨åˆ†é …ç›®æˆåŠŸè™•ç†"
    elif rate >= 50:
        interp = "ä¸€èˆ¬ï¼šç´„åŠæ•¸é …ç›®è™•ç†æˆåŠŸï¼Œéƒ¨åˆ†ä¾†æºå¯èƒ½æœ‰å•é¡Œ"
    else:
        interp = "ç•°å¸¸ï¼šå¤šæ•¸é …ç›®è™•ç†å¤±æ•—ï¼Œéœ€ç«‹å³æ’æŸ¥"
    lines.append(f"| Enrich Success Rate | {rate:.0f}% | {interp} | â‰¥ 80% |")

    # å¤±æ•—åŸå› 
    if health.fail_reasons:
        reasons_str = "; ".join(f"{translate_fail_reason(k)}Ã—{v}" for k, v in health.fail_reasons.items())
        lines.append(f"| Top Fail Reasons | è¦‹ä¸‹ | {reasons_str} | ç„¡å¤±æ•—ç‚ºæœ€ä½³ |")

    # å»¶é²
    p50_interp = "æ­£å¸¸" if health.p50_latency < 10 else ("åæ…¢" if health.p50_latency < 20 else "ç•°å¸¸ç·©æ…¢")
    lines.append(f"| Latency P50 | {health.p50_latency:.1f}s | {p50_interp} | < 10s |")
    p95_interp = "æ­£å¸¸" if health.p95_latency < 20 else ("åæ…¢" if health.p95_latency < 40 else "ç•°å¸¸ç·©æ…¢")
    lines.append(f"| Latency P95 | {health.p95_latency:.1f}s | {p95_interp} | < 30s |")

    # åŸ·è¡Œæ™‚é–“
    lines.append(f"| Total Runtime | {health.total_runtime:.1f}s | â€” | ä¾è³‡æ–™é‡è€Œå®š |")

    # é›œè¨Šæ¸…é™¤
    lines.append(f"| Entity Noise Removed | {health.entity_noise_removed} | {'å·²æ¸…é™¤éƒ¨åˆ†é›œè¨Šå¯¦é«”' if health.entity_noise_removed > 0 else 'ç„¡éœ€æ¸…é™¤'} | â€” |")

    lines.extend(["", ""])

    # ç´…é»ƒç¶ ç‡ˆ
    lines.extend([
        f"### {health.traffic_light_emoji} ç¸½é«”è©•ä¼°ï¼š{health.traffic_light_label}",
        "",
    ])

    # æ’éŒ¯æŒ‡ä»¤
    lines.extend([
        "### æ’éŒ¯æŒ‡å¼•",
        "",
        "**ğŸ” å¿«é€Ÿï¼šæŸ¥çœ‹æœ€è¿‘çš„éŒ¯èª¤ log**",
        "",
        "```powershell",
        "# PowerShell",
        'Select-String -Path ".\\logs\\app.log" -Pattern "ERROR|WARN" | Select-Object -Last 20',
        "```",
        "",
        "```bash",
        "# Bash",
        'grep -E "ERROR|WARN" logs/app.log | tail -20',
        "```",
        "",
        "**ğŸ”§ ä¸­ç­‰ï¼šç¯©é¸ç‰¹å®šéšæ®µçš„ log**",
        "",
        "```powershell",
        '# æŸ¥ Z5 æ•™è‚²ç‰ˆç›¸é—œ',
        'Select-String -Path ".\\logs\\app.log" -Pattern "Z5|education|Education"',
        '# æŸ¥æŠ“å–å¤±æ•—',
        'Select-String -Path ".\\logs\\app.log" -Pattern "enrich.*fail|blocked|timeout"',
        "```",
        "",
        "```bash",
        'grep -iE "Z5|education" logs/app.log',
        'grep -iE "enrich.*fail|blocked|timeout" logs/app.log',
        "```",
        "",
        "**ğŸ› ï¸ æ·±å…¥ï¼šé‡è·‘æˆ–èª¿æ•´ä¾†æº**",
        "",
        "```powershell",
        '# é—œé–‰ç‰¹å®šä¾†æºï¼ˆåœ¨ .env ä¸­ä¿®æ”¹ RSS_FEEDS_JSONï¼‰',
        '# æˆ–èª¿ä½å“è³ªé–€æª»åšæ¸¬è©¦',
        '# GATE_MIN_SCORE=5.0 python scripts\\run_once.py',
        "```",
        "",
    ])

    # ä¸‹ä¸€ Sprint å»ºè­°
    lines.extend([
        "### ä¸‹ä¸€ Sprint å»ºè­°",
        "",
        "1. **æé«˜æŠ“å–æˆåŠŸç‡**ï¼šæª¢æŸ¥ `core/ingestion.py` ä¸­çš„é‡è©¦é‚è¼¯èˆ‡ User-Agent è¨­å®š",
        "2. **é™ä½ P95 å»¶é²**ï¼šåœ¨ `core/ai_core.py` ä¸­å¢åŠ é€£ç·šæ± æˆ–ä¸¦è¡Œè™•ç†",
        "3. **æ”¹å–„å¯¦é«”æ¸…æ´—**ï¼šæ“´å…… `utils/entity_cleaner.py` ä¸­çš„è¦å‰‡ï¼Œæ¸›å°‘ false positive",
        "4. **ä¾†æºå“è³ªç›£æ§**ï¼šç‚ºæ¯å€‹ RSS ä¾†æºå»ºç«‹ç¨ç«‹çš„æˆåŠŸç‡è¿½è¹¤ï¼ˆå¯åœ¨ `utils/metrics.py` æ“´å……ï¼‰",
        "5. **æ•™è‚²ç‰ˆå…§å®¹æ·±åº¦**ï¼šæ ¹æ“šè®€è€…å›é¥‹èª¿æ•´ `core/education_renderer.py` ä¸­çš„è§£è®€æ¨¡æ¿",
        "",
    ])

    return lines


# ---------------------------------------------------------------------------
# PPT åˆ‡é ç‰ˆæ¸²æŸ“ï¼ˆæˆäººç‰ˆï¼šæ¯é æœ€å¤š 10 è¡Œï¼‰
# ---------------------------------------------------------------------------


def _render_ppt_md(
    cards: list[EduNewsCard],
    health: SystemHealthReport,
    report_time: str,
    total_items: int,
) -> str:
    pages: list[str] = []
    valid_count = sum(1 for c in cards if c.is_valid_news)
    invalid_count = len(cards) - valid_count

    # å°é¢é 
    pages.append(
        f"# ğŸ¤– AI æ·±åº¦æƒ…å ±åˆ†æå ±å‘Š\n\n"
        f"ğŸ“… {report_time}\n"
        f"ğŸ“Š åˆ†æ {total_items} å‰‡ï¼ˆæœ‰æ•ˆ {valid_count}ã€ç„¡æ•ˆ {invalid_count}ï¼‰\n"
        f"âœ… æˆåŠŸç‡ {health.success_rate:.0f}% ï½œ â±ï¸ {health.total_runtime:.1f}s\n\n"
        f"{health.traffic_light_emoji} {health.traffic_light_label}"
    )

    # ä»Šæ—¥çµè«–é 
    valid_cards = [c for c in cards if c.is_valid_news]
    titles = "ã€".join(c.title_plain[:12] for c in valid_cards[:3])
    pages.append(
        f"## ğŸ“Š ä»Šæ—¥çµè«–\n\n"
        f"æœ‰æ•ˆæ–°è {valid_count} å‰‡ ï½œ ç„¡æ•ˆ {invalid_count} å‰‡\n"
        f"ä¸»é¡Œæ¶µè“‹ï¼š{titles if titles else 'ç„¡'}\n"
        f"è³‡æ–™å¯ä¿¡åº¦ï¼š{'è‰¯å¥½' if health.success_rate >= 80 else 'ä¸­ç­‰' if health.success_rate >= 50 else 'åä½'}\n\n"
        f"{'â†’ ç³»çµ±é‹ä½œæ­£å¸¸' if health.traffic_light == 'green' else 'â†’ éƒ¨åˆ†é …ç›®éœ€é—œæ³¨' if health.traffic_light == 'yellow' else 'â†’ å»ºè­°æ’æŸ¥ç•°å¸¸'}"
    )

    # æµç¨‹åœ–é 
    pages.append(
        "## ğŸ—ºï¸ ç³»çµ±æµç¨‹\n\n"
        "```mermaid\n"
        "flowchart LR\n"
        "    A[RSS ä¾†æº] --> B[Z1 æ“·å–]\n"
        "    B --> C[Z2 AI åˆ†æ]\n"
        "    C --> D[Z3 å„²å­˜]\n"
        "    D --> E[Z4 æ·±åº¦åˆ†æ]\n"
        "    E --> F[Z5 æ•™è‚²ç‰ˆ]\n"
        "```"
    )

    # æ¯å‰‡æ–°è 2-4 é 
    for i, card in enumerate(cards, 1):
        tag = "âš ï¸ ç„¡æ•ˆ" if not card.is_valid_news else f"#{i}"

        if not card.is_valid_news:
            pages.append(
                f"## {tag}ï¼šéæ–°èå…§å®¹\n\n"
                f"**åˆ¤å®šï¼š** ç„¡æ•ˆï¼ˆç³»çµ±è¨Šæ¯ï¼‰\n"
                f"**åŸå› ï¼š** {card.invalid_cause or 'æŠ“å–å¤±æ•—'}\n"
                f"**ä¿®å¾©ï¼š** {card.invalid_fix or 'èª¿æ•´æŠ“å–ç­–ç•¥'}\n\n"
                f"â†’ æ­¤é …ç›®ä¸å«æœ‰æ•ˆæ–°èè³‡è¨Š"
            )
            continue

        # é  1ï¼šæ‘˜è¦
        what = card.what_happened[:80]
        why = card.why_important[:80]
        focus = card.focus_action[:80]
        pages.append(
            f"## {tag}ï¼š{card.title_plain[:30]}\n\n"
            f"**ç™¼ç”Ÿäº†ä»€éº¼ï¼š** {what}\n\n"
            f"**ç‚ºä»€éº¼é‡è¦ï¼š** {why}\n\n"
            f"**é—œæ³¨é‡é»ï¼š** {focus}"
        )

        # é  2ï¼šäº‹å¯¦ + è­‰æ“š
        facts_text = "\n".join(f"- âœ… {f[:60]}" for f in card.fact_check_confirmed[:3])
        ev_text = "\n".join(f"- {e[:70]}" for e in card.evidence_lines[:3])
        pages.append(
            f"## {tag}ï¼ˆçºŒï¼‰äº‹å¯¦æ ¸å° & è­‰æ“š\n\n"
            f"**äº‹å¯¦æ ¸å°ï¼š**\n{facts_text}\n\n"
            f"**è­‰æ“šç‰‡æ®µï¼š**\n{ev_text}"
        )

        # é  3ï¼šè¡Œå‹• + é¢¨éšª
        act_text = "\n".join(f"- {a[:70]}" for a in card.action_items[:3])
        effects_text = "\n".join(f"- {e[:60]}" for e in card.derivable_effects[:2])
        pages.append(
            f"## {tag}ï¼ˆçºŒï¼‰è¡Œå‹•å»ºè­° & å½±éŸ¿\n\n"
            f"**å¯åŸ·è¡Œè¡Œå‹•ï¼š**\n{act_text}\n\n"
            f"**ç›´æ¥å½±éŸ¿ï¼š**\n{effects_text if effects_text else '- ï¼ˆè³‡æ–™ä¸è¶³ï¼‰'}"
        )

    # Metrics é 
    pages.append(
        f"## ğŸ“Š ç³»çµ±æ•ˆèƒ½\n\n"
        f"| æŒ‡æ¨™ | æ•¸å€¼ |\n"
        f"|------|------|\n"
        f"| æˆåŠŸç‡ | {health.success_rate:.0f}% |\n"
        f"| P50 å»¶é² | {health.p50_latency:.1f}s |\n"
        f"| P95 å»¶é² | {health.p95_latency:.1f}s |\n"
        f"| é›œè¨Šæ¸…é™¤ | {health.entity_noise_removed} å€‹ |\n\n"
        f"{health.traffic_light_emoji} {health.traffic_light_label}"
    )

    return "\n\n---\n\n".join(pages) + "\n"


# ---------------------------------------------------------------------------
# XMind éšå±¤å¤§ç¶±ç‰ˆ
# ---------------------------------------------------------------------------


def _render_xmind_md(
    cards: list[EduNewsCard],
    health: SystemHealthReport,
    report_time: str,
    total_items: int,
) -> str:
    """æ¸²æŸ“ XMind å‹å–„çš„ç´”éšå±¤å¤§ç¶±ï¼ˆ2 ç©ºæ ¼ç¸®æ’ï¼‰ã€‚"""
    lines: list[str] = []
    date_str = report_time.split(" ")[0] if " " in report_time else report_time

    lines.append(f"AI æ·±åº¦æƒ…å ±åˆ†æï¼ˆ{date_str}ï¼‰")
    lines.append("  ä»Šæ—¥çµè«–")
    valid_count = sum(1 for c in cards if c.is_valid_news)
    invalid_count = len(cards) - valid_count
    lines.append(f"    æœ‰æ•ˆæ–°è {valid_count} å‰‡")
    lines.append(f"    ç„¡æ•ˆå…§å®¹ {invalid_count} å‰‡")
    lines.append(f"    æˆåŠŸç‡ {health.success_rate:.0f}%")
    lines.append(f"    å¥åº·åº¦ {health.traffic_light_label}")

    lines.append("  ç³»çµ±æµç¨‹ï¼ˆZ1-Z5ï¼‰")
    lines.append("    Z1 è³‡æ–™æ“·å–")
    lines.append("    Z2 AI åˆ†ææ ¸å¿ƒ")
    lines.append("    Z3 å„²å­˜èˆ‡äº¤ä»˜")
    lines.append("    Z4 æ·±åº¦åˆ†æ")
    lines.append("    Z5 æ•™è‚²ç‰ˆè½‰è­¯")

    for i, card in enumerate(cards, 1):
        title = card.title_plain[:30]
        if not card.is_valid_news:
            lines.append(f"  ç„¡æ•ˆé …ç›® {i}ï¼š{title}")
            lines.append("    åˆ¤å®šï¼šç„¡æ•ˆå…§å®¹")
            lines.append(f"    åŸå› ï¼š{card.invalid_cause or 'æŠ“å–å¤±æ•—'}")
            lines.append(f"    ä¿®å¾©ï¼š{card.invalid_fix or 'èª¿æ•´ç­–ç•¥'}")
            continue

        lines.append(f"  æ–°è {i}ï¼š{title}")
        lines.append("    æ‘˜è¦")
        lines.append(f"      ç™¼ç”Ÿäº†ä»€éº¼ï¼š{card.what_happened[:50]}")
        lines.append(f"      ç‚ºä»€éº¼é‡è¦ï¼š{card.why_important[:50]}")
        lines.append(f"      é—œæ³¨é‡é»ï¼š{card.focus_action[:50]}")

        lines.append("    äº‹å¯¦æ ¸å°")
        for fact in card.fact_check_confirmed[:3]:
            lines.append(f"      âœ… {fact[:50]}")
        for uv in card.fact_check_unverified[:2]:
            lines.append(f"      âš ï¸ {uv[:50]}")

        lines.append("    è­‰æ“š")
        for ev in card.evidence_lines[:3]:
            lines.append(f"      {ev[:60]}")

        lines.append("    æŠ€è¡“è§£è®€")
        if card.technical_interpretation:
            # åˆ†æˆå¤šè¡Œ
            interp = card.technical_interpretation[:120]
            lines.append(f"      {interp}")

        lines.append("    äºŒéšæ•ˆæ‡‰")
        for eff in card.derivable_effects[:2]:
            lines.append(f"      ç›´æ¥ï¼š{eff[:50]}")
        for eff in card.speculative_effects[:2]:
            lines.append(f"      é–“æ¥ï¼š{eff[:50]}")

        lines.append("    è¡Œå‹•å»ºè­°")
        for act in card.action_items[:3]:
            lines.append(f"      {act[:60]}")

        lines.append("    ç´ æ")
        for img in card.image_suggestions[:1]:
            lines.append(f"      {img[:60]}")
        for vid in card.video_suggestions[:1]:
            lines.append(f"      {vid[:60]}")

    lines.append("  Metrics & é‹ç¶­")
    lines.append(f"    æˆåŠŸç‡ {health.success_rate:.0f}%")
    lines.append(f"    P50 å»¶é² {health.p50_latency:.1f}s")
    lines.append(f"    P95 å»¶é² {health.p95_latency:.1f}s")
    lines.append(f"    é›œè¨Šæ¸…é™¤ {health.entity_noise_removed} å€‹")
    lines.append(f"    å¥åº·åº¦ {health.traffic_light_emoji} {health.traffic_light_label}")
    if health.fail_reasons:
        lines.append("    å¤±æ•—åŸå› ")
        for reason, count in health.fail_reasons.items():
            lines.append(f"      {translate_fail_reason(reason)} Ã—{count}")

    return "\n".join(lines) + "\n"


# ---------------------------------------------------------------------------
# å…¬é–‹ API
# ---------------------------------------------------------------------------


def render_education_report(
    results: list[MergedResult] | None = None,
    report: DeepAnalysisReport | None = None,
    metrics: dict[str, Any] | None = None,
    deep_analysis_text: str | None = None,
    max_items: int = 0,
    filter_summary: dict[str, Any] | None = None,
) -> tuple[str, str, str]:
    """Z5 ä¸»å…¥å£ï¼šç”Ÿæˆæˆäººæ•™è‚²ç‰ˆå ±å‘Šã€‚

    æ¨¡å¼ Aï¼ˆå„ªå…ˆï¼‰ï¼šå‚³å…¥ results + report + metrics
    æ¨¡å¼ Bï¼ˆfallbackï¼‰ï¼šå‚³å…¥ deep_analysis_text + metrics

    å›å‚³ (notion_md, ppt_md, xmind_md) ä¸‰ä»½ Markdown å­—ä¸²ã€‚
    """
    log = get_logger()
    log.info("--- Z5: Education Renderer é–‹å§‹ ---")

    now = datetime.now().strftime("%Y-%m-%d %H:%M æœ¬æ©Ÿæ™‚å€")

    if metrics is None:
        metrics = {}
    health = _parse_metrics_dict(metrics)
    total_items = int(metrics.get("total_items", 0))

    cards: list[EduNewsCard] = []

    # æ¨¡å¼ Aï¼šçµæ§‹åŒ–è¼¸å…¥
    if results is not None and report is not None:
        log.info("Z5: ä½¿ç”¨æ¨¡å¼ Aï¼ˆçµæ§‹åŒ–è¼¸å…¥ï¼‰ï¼Œ%d å‰‡çµæœ", len(results))
        dive_map: dict[str, ItemDeepDive] = {}
        for dive in report.per_item_analysis:
            dive_map[dive.item_id] = dive

        for i, r in enumerate(results):
            dive = dive_map.get(r.item_id)
            card = _build_card_from_structured(r, dive, i)
            cards.append(card)

        if report.generated_at:
            now = report.generated_at
        if report.total_items:
            total_items = report.total_items

    # æ¨¡å¼ Bï¼šæ–‡æœ¬ fallback
    elif deep_analysis_text:
        log.info("Z5: ä½¿ç”¨æ¨¡å¼ Bï¼ˆæ–‡æœ¬ fallbackï¼‰")
        parsed_items = _parse_deep_analysis_text(deep_analysis_text)
        for i, parsed in enumerate(parsed_items):
            card = _build_card_from_parsed(parsed, i)
            cards.append(card)
        total_items = total_items or len(cards)

    else:
        log.warning("Z5: æ²’æœ‰å¯ç”¨çš„è¼¸å…¥è³‡æ–™ï¼Œç”Ÿæˆç©ºç™½å ±å‘Š")
        total_items = 0

    if max_items > 0 and len(cards) > max_items:
        cards = cards[:max_items]
        log.info("Z5: é™åˆ¶æœ€å¤§é …ç›®æ•¸ç‚º %d", max_items)

    log.info("Z5: å…±ç”Ÿæˆ %d å¼µæ•™è‚²ç‰ˆå¡ç‰‡", len(cards))

    notion_md = _render_notion_md(cards, health, now, total_items, metrics, filter_summary=filter_summary)
    ppt_md = _render_ppt_md(cards, health, now, total_items)
    xmind_md = _render_xmind_md(cards, health, now, total_items)

    log.info("--- Z5: Education Renderer å®Œæˆ ---")
    return notion_md, ppt_md, xmind_md


def write_education_reports(
    notion_md: str,
    ppt_md: str,
    xmind_md: str = "",
    project_root: Path | None = None,
) -> tuple[Path, Path, Path, Path]:
    """å¯«å…¥å››ä»½æ•™è‚²ç‰ˆå ±å‘Šæª”æ¡ˆã€‚

    å›å‚³ (notion_path, ppt_path, xmind_path, outputs_path)ã€‚
    """
    if project_root is None:
        project_root = Path(__file__).resolve().parent.parent

    docs_dir = project_root / "docs" / "reports"
    outputs_dir = project_root / "outputs"
    docs_dir.mkdir(parents=True, exist_ok=True)
    outputs_dir.mkdir(parents=True, exist_ok=True)

    notion_path = docs_dir / "deep_analysis_education_version.md"
    ppt_path = docs_dir / "deep_analysis_education_version_ppt.md"
    xmind_path = docs_dir / "deep_analysis_education_version_xmind.md"
    outputs_path = outputs_dir / "deep_analysis_education.md"

    notion_path.write_text(notion_md, encoding="utf-8")
    ppt_path.write_text(ppt_md, encoding="utf-8")
    xmind_path.write_text(xmind_md, encoding="utf-8")
    outputs_path.write_text(notion_md, encoding="utf-8")

    log = get_logger()
    log.info("Z5: æ•™è‚²ç‰ˆå ±å‘Šå·²å¯«å…¥ï¼š%s, %s, %s, %s", notion_path, ppt_path, xmind_path, outputs_path)

    return notion_path, ppt_path, xmind_path, outputs_path


def render_error_report(error: Exception) -> str:
    """Z5 å¤±æ•—æ™‚ï¼Œç”Ÿæˆä¸€ä»½ã€Œæ•™è‚²ç‰ˆç”Ÿæˆå¤±æ•—èªªæ˜ã€ã€‚"""
    import traceback
    tb = traceback.format_exception(type(error), error, error.__traceback__)
    tb_summary = "".join(tb[-3:]) if len(tb) > 3 else "".join(tb)

    return (
        "# âš ï¸ æ•™è‚²ç‰ˆå ±å‘Šç”Ÿæˆå¤±æ•—\n"
        "\n"
        f"**éŒ¯èª¤è¨Šæ¯ï¼š** `{error}`\n"
        "\n"
        "## éŒ¯èª¤è¿½è¹¤ï¼ˆTraceback æ‘˜è¦ï¼‰\n"
        "\n"
        "```\n"
        f"{tb_summary}"
        "```\n"
        "\n"
        "## ä¿®å¾©æ­¥é©Ÿ\n"
        "\n"
        "1. æª¢æŸ¥ `outputs/deep_analysis.md` æ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º\n"
        "2. æª¢æŸ¥ `outputs/metrics.json` æ˜¯å¦å­˜åœ¨ä¸”ç‚ºæœ‰æ•ˆ JSON\n"
        "3. æŸ¥çœ‹ `logs/app.log` ä¸­çš„ Z5 ç›¸é—œéŒ¯èª¤è¨Šæ¯\n"
        "4. ç¢ºèª `.env` ä¸­ `EDU_REPORT_ENABLED=true`\n"
        "5. ç¢ºèª Python ç‰ˆæœ¬ â‰¥ 3.10ï¼ˆæœ¬æ¨¡çµ„ä½¿ç”¨ `X | Y` å‹åˆ¥èªæ³•ï¼‰\n"
        "\n"
        "**å¿«é€Ÿæ’æŸ¥æŒ‡ä»¤ï¼š**\n"
        "\n"
        "```powershell\n"
        '# PowerShell\n'
        'Select-String -Path ".\\logs\\app.log" -Pattern "Z5|education" | Select-Object -Last 10\n'
        "```\n"
        "\n"
        "```bash\n"
        '# Bash\n'
        'grep -i "Z5\\|education" logs/app.log | tail -10\n'
        "```\n"
        "\n"
        "è‹¥ä»ç„¡æ³•è§£æ±ºï¼Œè«‹å°‡ä¸Šè¿° Traceback èˆ‡ log æä¾›çµ¦å·¥ç¨‹å¸«ã€‚\n"
    )

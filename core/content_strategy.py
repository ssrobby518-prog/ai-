"""Shared content-intelligence layer for executive output generators.

Centralizes:
- Curated/index page detection
- Non-event / index page filtering for CEO deck
- Grammar-safe sanitization (never creates broken sentences)
- 6-column decision card construction (no homework, no template sentences)
- CEO article blocks with real content
- Context-aware term explainer with curated dictionary
- Responsibility mapping

Used by: ppt_generator.py, doc_generator.py
"""

from __future__ import annotations

import re
from collections import Counter

from schemas.education_models import EduNewsCard

# ---------------------------------------------------------------------------
# Banned words — sanitize all output text
# ---------------------------------------------------------------------------
BANNED_WORDS = [
    "ai捕捉", "AI Intel", "Z1", "Z2", "Z3", "Z4", "Z5",
    "pipeline", "ETL", "verify_run", "ingestion", "ai_core",
]

# System-operation terms that must never appear in CEO output
_SYSTEM_WORDS_RE = re.compile(
    r"系統健康|系統運作|資料可信度|延遲|P95|雜訊清除|健康狀態|"
    r"pipeline|ingestion|資料完整率|traffic_light|success_rate|"
    r"latency_p95|noise_filtered",
    re.IGNORECASE,
)

# Patterns that indicate empty-talk / homework / template sentences
_HOMEWORK_PATTERNS = [
    r"本週內[：:]",
    r"→\s*產出[：:]",
    r"摘要筆記",
    r"搜尋[「『]",
    r"去查|去找|去搜",
    r"建議追蹤",
    r"值得持續觀察",
    r"反映.*重要.*趨勢",
    r"此事件反映",
    r"值得.*關注.*後續",
    r"兩週內[：:].*評估",
    r"產出[：:].*評估表",
    r"影響評估表",
    r"了當前的重要產業趨勢",
    r"與.*相關的技術或概念",
    r"領域在\s*\S+\s*方面存在.*缺口",
    r"可探索提供相關工具或解決方案",
    r"初步評估筆",
    r"重要產業趨勢",
    # Template sentences generated by the analysis pipeline
    r"領域的現有參與.*評估",
    r"將驅動相關方重新評估",
    r"這是.*領域的.*動態",
    r"對相關產業或使用者產生",
    r"相關方可能需要新的",
    r"需要評估相容性影響",
    r"As part of its mission",
    r"[」』].*?最新報導",
    r"[」』].*?最新趨勢",
    r"[」』].*?進展",
    r"對自身工作或投資的潛在影響",
    r"了解更多.*資訊",
    r"進一步了解",
    r"持續關注.*動向",
    r"的趨勢.*觀察",
    r"風險/機會清單",
]
_HOMEWORK_RE = re.compile("|".join(_HOMEWORK_PATTERNS), re.IGNORECASE)

# Pattern to detect "filler echo" — raw what_happened text echoed into analysis
# e.g. 基於「As much of Silicon Valley chases mega-rounds and...
_ECHO_RE = re.compile(
    r"基於[「『].*?[」』]|"
    r"事件的潛在影響[：:]|"
    r"\[假說\]\s*若[「『]",
    re.IGNORECASE,
)

# Keywords suggesting a curated/index/archive page rather than a single event
_INDEX_PAGE_KEYWORDS = [
    "curated list", "curated", "rss feed", "rss", "entries for the year",
    "collecting", "archive", "overview", "stats", "year in review",
    "changelog", "release notes list", "index of", "table of contents",
    "as part of its mission", "newsletter",
]

# Patterns that indicate non-event content (title/summary level)
_NON_EVENT_TITLE_PREFIXES = [
    r"^as part of its mission",
    r"^overview",
    r"^archive",
    r"^curated",
    r"^table of contents",
    r"^newsletter",
    r"^a list of",
    r"^collection of",
    # Personal blog / appreciation posts
    r"^for this year",
    r"^i love ",
    # Scraper artifacts (login pages, UI text)
    r"you must be signed",
    r"sign(ed)? in to",
    r"notification settings",
    r"^show hn:",
]
_NON_EVENT_TITLE_RE = re.compile(
    "|".join(_NON_EVENT_TITLE_PREFIXES), re.IGNORECASE
)

# Event action verbs (Chinese + English) — at least one must appear for event
_EVENT_VERBS_RE = re.compile(
    r"推出|收購|禁用|發布|漏洞|裁員|上調|下調|立法|訴訟|"
    r"投資|併購|開源|下架|召回|罰款|合併|關閉|暫停|擴張|"
    r"launch|acquir|ban|releas|vulnerabilit|layoff|raise|lower|"
    r"legislat|sued|invest|merg|open.?source|remov|recall|fine|"
    r"shut|suspend|expand|block|hide|filter|maintain|operat|"
    r"announc|introduc|report|discover|breach|hack|leak|"
    r"partner|fund|grant|approve|reject|delay|cancel|"
    r"happen|develop|reveal|confirm|warn|impact|affect|change",
    re.IGNORECASE,
)

# Responsibility mapping for "要問誰" column
RESPONSIBILITY_MAP = {
    "綜合": "策略長/PM",
    "tech": "策略長/PM",
    "科技/技術": "研發/CTO",
    "人工智慧": "研發/CTO",
    "資安": "資安長",
    "政策/監管": "法務",
    "法規": "法務",
    "金融/財經": "財務長/CFO",
    "創業/投融資": "策略長/PM",
    "氣候/能源": "營運/COO",
    "併購/企業": "策略長/CEO",
    "消費電子": "產品/PM",
    "遊戲/娛樂": "產品/PM",
    "雲": "研發/CTO",
    "AI": "研發/CTO",
    "工程": "研發/CTO",
    "產品": "產品/PM",
    "市場": "產品/市場",
}


# ---------------------------------------------------------------------------
# Sanitization — grammar-safe, never creates broken sentences
# ---------------------------------------------------------------------------


def sanitize(text: str) -> str:
    """Remove banned words, then strip homework/template sentences.

    Fragment-replacement approach: replaces matched phrases instead
    of deleting entire sentences, then repairs broken Chinese grammar.
    """
    if not text:
        return ""
    result = text
    for bw in BANNED_WORDS:
        result = result.replace(bw, "")
    # Remove system operation terms
    result = _SYSTEM_WORDS_RE.sub("", result)
    # Replace homework fragments
    result = _HOMEWORK_RE.sub("", result).strip()
    # Remove echo-filler patterns
    result = _ECHO_RE.sub("", result).strip()
    # Chinese grammar repair: fix dangling connectors at sentence start
    result = re.sub(r"^[了而並且因此所以但是然而]+", "", result)
    result = re.sub(r"(?<=[。！？\n])[了而並且因此所以但是然而]+", "", result)
    # Fix broken punctuation
    result = re.sub(r"。。+", "。", result)
    result = re.sub(r"[「」『』]\s*[「」『』]", "", result)
    # Remove orphaned closing quotes (」not preceded by matching 「)
    result = re.sub(r"(?<![「『])[」』]", "", result)
    result = re.sub(r"^\s*[，。；：]+", "", result)
    result = re.sub(r"\s{2,}", " ", result).strip()
    # If result is empty or too short after cleanup, return empty
    if len(result) < 3:
        return ""
    # Detect broken fragments left after pattern removal
    # e.g. "，的機會 記" or "的趨勢，" orphans
    if re.search(r"，的[^，。]{0,6}[記表]|^[，的。]{1,4}$", result):
        return ""
    # If mostly punctuation / whitespace, discard
    alpha_count = sum(1 for c in result if c.isalnum())
    if alpha_count < max(3, len(result) * 0.3):
        return ""
    return result


def _smart_truncate(text: str, limit: int) -> str:
    """Truncate at sentence/word boundary. Never mid-word or dangling Chinese."""
    if len(text) <= limit:
        return text
    cut = text[:limit]
    # Try sentence boundary first (Chinese punctuation, then English period)
    for sep in ["。", "！", "？", "；", ". ", "，"]:
        pos = cut.rfind(sep)
        if pos > limit * 0.5:
            return cut[:pos + len(sep)].rstrip()
    # Try word boundary (space)
    pos = cut.rfind(" ")
    if pos > limit * 0.5:
        return cut[:pos].rstrip() + "…"
    return cut.rstrip() + "…"


def responsible_party(category: str) -> str:
    """Map category to responsible party."""
    cat = (category or "").strip()
    if cat in RESPONSIBILITY_MAP:
        return RESPONSIBILITY_MAP[cat]
    cat_lower = cat.lower()
    for key, val in RESPONSIBILITY_MAP.items():
        if key.lower() in cat_lower or cat_lower in key.lower():
            return val
    return "策略長/PM"


# ---------------------------------------------------------------------------
# Non-event / index page detection
# ---------------------------------------------------------------------------


def is_index_page(card: EduNewsCard) -> bool:
    """Detect if a card represents a curated/index/archive page, not a single event."""
    combined = f"{card.title_plain} {card.what_happened}".lower()
    hits = sum(1 for kw in _INDEX_PAGE_KEYWORDS if kw in combined)
    return hits >= 1


def is_non_event_or_index(card: EduNewsCard) -> bool:
    """Strong filter: detect index pages AND content lacking event substance.

    Returns True (= should be excluded from CEO deck) if:
    - Title starts with known non-event prefixes, OR
    - Content is an index/archive page, OR
    - Content lacks 2+ of the 3 event elements: subject, action, time
    """
    title = (card.title_plain or "").strip()
    summary = (card.what_happened or "").strip()
    one_liner = getattr(card, "one_liner", "") or ""
    combined = f"{title} {summary} {one_liner}"

    # Check title prefixes
    if _NON_EVENT_TITLE_RE.search(title):
        return True

    # Check index page keywords
    if is_index_page(card):
        return True

    # Check event substance: subject + action + time
    has_action = bool(_EVENT_VERBS_RE.search(combined))
    has_time = bool(re.search(
        r"20\d{2}|本週|昨日|今日|近日|日前|上週|本月|今年|yesterday|today|"
        r"this week|last week|recently|Monday|Tuesday|Wednesday|Thursday|"
        r"Friday|Q[1-4]|January|February|March|April|May|June|July|"
        r"August|September|October|November|December",
        combined, re.IGNORECASE,
    ))
    # Subject: any recognizable proper noun (capitalized word >=3 chars)
    has_subject = bool(re.search(r"[A-Z][a-z]{2,}", combined))

    elements = sum([has_action, has_time, has_subject])
    # Allow missing 1 element, but not 2+
    if elements <= 1:
        return True

    return False


def _clean_text(text: str, max_len: int) -> str:
    """Sanitize + truncate."""
    return _smart_truncate(sanitize(text), max_len) if text else ""


# ---------------------------------------------------------------------------
# 6-column decision card builder
# ---------------------------------------------------------------------------


def build_decision_card(card: EduNewsCard) -> dict[str, list[str] | str]:
    """Build a structured 6-column decision card from an EduNewsCard.

    Returns dict with keys: event, facts, effects, risks, actions, owner.
    Each value is either a str or list[str].
    All text is sanitized and free of homework/template sentences.
    """
    is_index = is_index_page(card)
    owner = responsible_party(card.category)

    # 1) 事件一句話 (≤22 chars)
    if is_index:
        event = "來源疑似彙整索引頁，非單一事件"
    else:
        raw_event = _clean_text(card.what_happened or "", 22)
        event = raw_event if raw_event and len(raw_event) > 4 else "事件摘要資料不足"

    # 2) 已知事實 (3 points) — ONLY from fact_check/evidence, never from what_happened
    facts: list[str] = []
    if is_index:
        if card.title_plain:
            facts.append(f"來源標題：{_clean_text(card.title_plain, 50)}")
        facts.append("缺口：此頁為彙整/索引，無法提取單一事件的事實")
    else:
        for f in (card.fact_check_confirmed or [])[:3]:
            cleaned = _clean_text(f, 55)
            if cleaned and len(cleaned) > 5:
                facts.append(cleaned)
        if not facts:
            for e in (card.evidence_lines or [])[:3]:
                cleaned = _clean_text(e, 55)
                if cleaned and len(cleaned) > 5:
                    facts.append(cleaned)

    gap_templates = [
        "缺口：缺可驗證來源或原始出處",
        "缺口：缺事件時間或主體",
        "缺口：缺第三方佐證",
    ]
    gi = 0
    while len(facts) < 3 and gi < len(gap_templates):
        if gap_templates[gi] not in facts:
            facts.append(gap_templates[gi])
        gi += 1

    # 3) 可能影響 (2-3 points) — from derivable_effects ONLY, no what_happened echo
    effects: list[str] = []
    if is_index:
        effects = [
            "若此來源多為索引頁，會稀釋每日情報的決策價值",
            "資訊來源品質下降可能導致漏抓真正的重要事件",
        ]
    else:
        for eff in (card.derivable_effects or [])[:3]:
            cleaned = _clean_text(eff, 50)
            if cleaned and len(cleaned) > 5 and not _HOMEWORK_RE.search(cleaned):
                effects.append(cleaned)
        if not effects:
            # Try why_important as a single fallback, but DON'T echo what_happened
            if card.why_important:
                cleaned = _clean_text(card.why_important, 50)
                if cleaned and len(cleaned) > 10 and not _HOMEWORK_RE.search(cleaned):
                    effects.append(cleaned)
        if not effects:
            effects.append("缺口：影響面尚待分析（原始資料不足）")

    # 4) 主要風險 (2 points) — from speculative_effects ONLY
    risks: list[str] = []
    if is_index:
        risks = [
            "若持續納入索引頁，可能遮蔽真正需要決策的事件",
            "資料品質下降→決策基礎受損",
        ]
    else:
        for r in (card.speculative_effects or [])[:2]:
            cleaned = _clean_text(r, 50)
            if cleaned and len(cleaned) > 5 and not _HOMEWORK_RE.search(cleaned):
                risks.append(cleaned)
        if not risks:
            risks.append("缺口：風險評估需更多背景資料")

    # 5) 建議決策/動作 (1-2 points) — NEVER homework, NEVER echo what_happened
    actions: list[str] = []
    if is_index:
        actions = [
            "確認：保留此來源或降權/移除？",
            "指派負責人評估此來源的資訊品質",
        ]
    else:
        for a in (card.action_items or [])[:2]:
            cleaned = _clean_text(a, 55)
            if (cleaned and len(cleaned) > 5
                    and not _HOMEWORK_RE.search(cleaned)
                    and not _ECHO_RE.search(cleaned)):
                actions.append(cleaned)
        if not actions:
            actions.append("確認此事件是否影響現有業務或專案排程")

    return {
        "event": event[:22],
        "facts": facts[:3],
        "effects": effects[:3],
        "risks": risks[:2],
        "actions": actions[:2],
        "owner": owner,
    }


# ---------------------------------------------------------------------------
# Key term extraction — strict: only technical/proper nouns, never common words
# ---------------------------------------------------------------------------

_STOP_WORDS = {
    # Common English — aggressively broad to prevent "changed", "landscape", etc.
    "the", "and", "for", "are", "but", "not", "you", "all", "can", "had",
    "her", "was", "one", "our", "out", "has", "his", "how", "its", "may",
    "new", "now", "old", "see", "way", "who", "did", "get", "let", "say",
    "she", "too", "use", "with", "this", "that", "from", "have", "been",
    "will", "more", "when", "some", "than", "them", "what", "your", "each",
    "make", "like", "into", "over", "such", "take", "year", "also", "back",
    "could", "would", "about", "after", "other", "which", "their", "there",
    "first", "these", "those", "being", "where", "every", "should", "because",
    "http", "https", "www", "com", "org", "html", "json", "xml", "url",
    "via", "per", "etc", "just", "very", "much", "most", "only", "then",
    "here", "well", "still", "even", "does", "done", "going", "want",
    "said", "says", "many", "been", "were", "they", "them", "both",
    "same", "while", "during", "before", "since", "between", "under",
    "within", "through", "already", "several", "another", "however",
    "including", "according", "although", "using", "based", "part",
    "report", "reports", "reported", "company", "companies", "people",
    "data", "time", "made", "last", "next", "down", "help", "show",
    "shows", "showed", "look", "need", "needs", "work", "works",
    "plan", "plans", "move", "call", "called", "keep", "start",
    "started", "come", "came", "think", "given", "give", "gave",
    "found", "find", "known", "know", "long", "high", "lead",
    "early", "late", "left", "right", "real", "open", "test",
    "tests", "tested", "added", "used", "set", "run", "big",
    "file", "files", "page", "pages", "link", "links", "site",
    "image", "images", "text", "click", "view", "read", "list",
    "item", "items", "type", "name", "code", "line", "lines",
    "source", "content", "title", "post", "blog", "web",
    "major", "latest", "recent", "global", "full", "total",
    "million", "billion", "percent", "number", "version",
    # Additional generic words that are NOT technical terms
    "mission", "preserve", "maintained", "traces", "hide",
    "videos", "operating", "operates", "capture", "snapshots",
    "increasingly", "becoming", "unarchivable", "part",
    # Common English words that got extracted as "terms" incorrectly
    "changed", "landscape", "exec", "doubling", "running", "chases",
    "deals", "buzzy", "throwback", "venture", "capital", "like",
    "world", "important", "something", "happened", "tech",
    "news", "good", "best", "better", "worse", "small", "large",
    "also", "really", "actually", "basically", "probably",
    "today", "yesterday", "tomorrow", "week", "month",
    "says", "told", "asked", "means", "think", "working",
    "trying", "getting", "making", "taking", "looking",
    "going", "coming", "putting", "turning", "building",
    "growing", "moving", "changing", "becoming", "running",
    "saying", "doing", "having", "seeing", "giving",
    "different", "specific", "particular", "general", "possible",
    "certain", "likely", "clear", "strong", "among", "across",
    "around", "against", "along", "beyond", "toward",
    "nearly", "almost", "above", "below", "enough", "rather",
    "instead", "whether", "though", "behind", "might",
    "model", "system", "process", "service", "platform",
    "network", "market", "product", "business", "industry",
    "level", "point", "issue", "state", "order", "place",
    "power", "group", "thing", "world", "money", "family",
    "story", "fact", "month", "night", "school", "three",
    "human", "local", "small", "large", "young", "public",
    "early", "often", "those", "whole", "whose", "bring",
    "shall", "being", "among", "allow", "begin", "would",
    # Common English words that appear capitalized at sentence start
    "free", "software", "folders", "department", "homeland",
    "fork", "settings", "notification", "signed", "myself",
    "leader", "day", "love", "thank", "documentation",
    "pressure", "identify", "owners", "accounts", "hundreds",
    "border", "information", "increasing", "project",
    "entries", "collecting", "maintainers", "maintained",
    "written", "ported", "trust", "anymore", "header",
    "library", "review", "disc", "archival", "capability",
    "bookmark", "manager", "radar", "live", "threat",
    "cyber", "intelligence", "grid", "client", "sent",
    "reportedly", "hundreds", "requests", "like",
    "compiler", "amsterdam", "deep", "single", "origin",
    "arch", "desc", "threat", "tool", "tools", "user", "users",
}

# Only extract words that look like actual terms (capitalized, or contain digits/hyphens)
_TERM_RE = re.compile(r"[A-Za-z][A-Za-z0-9-]{2,}")


# ---------------------------------------------------------------------------
# Curated term dictionary (CEO-readable, white-language)
# ---------------------------------------------------------------------------
TERM_DICTIONARY: dict[str, dict[str, str]] = {
    # Internet / Web
    "internet archive": {
        "what": "一個非營利組織，專門保存網頁、書籍、影片的歷史副本",
        "biz": "若公司網站內容被保存，可能暴露舊版頁面或已修正的資訊",
    },
    "ublock origin": {
        "what": "一款免費的瀏覽器廣告攔截外掛，可過濾網頁廣告和追蹤器",
        "biz": "若用戶大量使用，會直接減少公司線上廣告的觸及率和收入",
    },
    "filter list": {
        "what": "一份規則清單，告訴攔截工具哪些網頁元素要隱藏或封鎖",
        "biz": "新的過濾規則可能影響公司產品頁面的顯示或廣告投放效果",
    },
    "youtube shorts": {
        "what": "YouTube 的短影片功能，類似 TikTok 的直式短影片",
        "biz": "短影片是目前社群行銷主力管道，若被過濾會影響觸及率",
    },
    "web crawler": {
        "what": "自動瀏覽網頁並下載內容的程式，搜尋引擎就是靠它收集資料",
        "biz": "爬蟲政策影響公司網站的 SEO 排名和資料被第三方使用的方式",
    },
    "webpage snapshot": {
        "what": "某個時間點的網頁完整備份，像是幫網頁拍照存檔",
        "biz": "舊版網頁快照可能被用於法律舉證或競爭對手情報分析",
    },
    "open source": {
        "what": "程式碼公開、任何人都能檢視和修改的軟體開發模式",
        "biz": "採用開源可降低授權成本，但需評估維護責任和安全風險",
    },
    "api": {
        "what": "不同軟體之間溝通的標準介面，像是餐廳的點餐窗口",
        "biz": "API 品質直接影響產品整合速度和合作夥伴的接入體驗",
    },
    "saas": {
        "what": "透過網路訂閱使用的軟體服務，不需自己安裝維護",
        "biz": "SaaS 模式影響公司的 IT 支出結構和資料控制權",
    },
    "ai": {
        "what": "人工智慧，讓電腦模擬人類思考和決策的技術",
        "biz": "AI 工具可提升效率但需評估準確性、成本和合規風險",
    },
    "llm": {
        "what": "大型語言模型，能理解和生成人類語言的 AI 系統",
        "biz": "可用於客服、內容生成、資料分析，但有幻覺和隱私風險",
    },
    "blockchain": {
        "what": "一種分散式帳本技術，資料一旦寫入就很難竄改",
        "biz": "可能影響供應鏈追溯、數位資產管理和跨境支付流程",
    },
    "cloud": {
        "what": "透過網路使用遠端伺服器的運算和儲存資源",
        "biz": "雲端成本和供應商鎖定是 IT 策略的核心決策點",
    },
    "cybersecurity": {
        "what": "保護電腦系統和資料不被未經授權存取或攻擊的措施",
        "biz": "資安事件可導致營運中斷、罰款和商譽損失",
    },
    "zero-day": {
        "what": "軟體中尚未被修補的安全漏洞，攻擊者可能已在利用",
        "biz": "零日漏洞代表最高風險等級，需立即評估受影響系統",
    },
    "ransomware": {
        "what": "會加密你的檔案並要求付贖金才解鎖的惡意程式",
        "biz": "勒索軟體可癱瘓整個營運，備份和應變計畫是關鍵防線",
    },
    "gdpr": {
        "what": "歐盟的個人資料保護法規，對資料收集和使用有嚴格規範",
        "biz": "違規罰款最高達全球營收 4%，影響所有有歐洲用戶的業務",
    },
    "iot": {
        "what": "物聯網，讓日常設備（感測器、家電等）連上網路互相溝通",
        "biz": "IoT 設備增加攻擊面，但也帶來自動化和數據收集機會",
    },
    "edge computing": {
        "what": "把運算放在靠近資料來源的地方處理，而非全送到雲端",
        "biz": "可降低延遲和頻寬成本，適合即時應用場景",
    },
    "kubernetes": {
        "what": "自動管理大量容器化應用程式的開源平台",
        "biz": "降低維運人力但學習門檻高，是雲端架構的核心技術選擇",
    },
    "docker": {
        "what": "把應用程式和所需環境打包成標準化容器的工具",
        "biz": "加速部署和環境一致性，是現代軟體交付的基礎設施",
    },
    "microservices": {
        "what": "把大系統拆成多個獨立小服務，各自開發部署",
        "biz": "提升開發速度但增加系統複雜度，需權衡團隊規模",
    },
    "devops": {
        "what": "開發和維運團隊緊密合作、自動化交付的工作方式",
        "biz": "DevOps 成熟度直接影響產品上線速度和系統穩定性",
    },
    "fintech": {
        "what": "運用科技改善金融服務的產業，如行動支付、線上借貸",
        "biz": "FinTech 競爭者可能侵蝕傳統金融業務的市場份額",
    },
    "quantum computing": {
        "what": "利用量子力學原理進行運算的新型電腦，部分問題可指數加速",
        "biz": "長期可能破解現有加密，短期影響有限但需開始規劃",
    },
    "5g": {
        "what": "第五代行動通訊技術，速度更快、延遲更低、連接更多設備",
        "biz": "5G 基礎建設影響遠端辦公、智慧工廠和新產品開發",
    },
    "ar": {
        "what": "擴增實境，在現實世界上疊加數位資訊的技術",
        "biz": "AR 可用於培訓、產品展示和遠端維修，降低實體成本",
    },
    "vr": {
        "what": "虛擬實境，用頭戴裝置沈浸在完全數位化的環境中",
        "biz": "VR 應用於培訓和協作，但硬體成本和使用者接受度是門檻",
    },
    "nft": {
        "what": "非同質化代幣，用區塊鏈證明數位物品的獨特性和所有權",
        "biz": "NFT 熱潮已降溫，但底層技術仍可用於數位資產認證",
    },
    "web3": {
        "what": "基於區塊鏈的去中心化網路願景，用戶擁有自己的數據",
        "biz": "Web3 概念尚在早期，投資需謹慎評估實際商業價值",
    },
    "semiconductor": {
        "what": "半導體，製造晶片的核心材料，驅動所有電子設備",
        "biz": "晶片供應影響產品交期和成本，是供應鏈的戰略性物資",
    },
    "x86-64": {
        "what": "個人電腦和伺服器最常用的處理器架構標準",
        "biz": "x86 生態系決定軟體相容性，架構轉移影響 IT 採購決策",
    },
    "arm": {
        "what": "一種低功耗處理器架構，廣泛用於手機和新型筆電",
        "biz": "ARM 架構在伺服器和筆電的崛起影響軟體開發和採購策略",
    },
    "gpu": {
        "what": "圖形處理器，擅長大量並行運算，是 AI 訓練的核心硬體",
        "biz": "GPU 供需和價格直接影響 AI 專案的成本和可行性",
    },
    "cpu": {
        "what": "中央處理器，電腦的運算核心，執行所有指令",
        "biz": "CPU 效能和供應影響伺服器成本和產品效能上限",
    },
    "nvidia": {
        "what": "全球最大的 GPU 晶片設計公司，AI 訓練硬體的主導者",
        "biz": "NVIDIA 的產品供應和定價直接影響 AI 專案可行性",
    },
    "openai": {
        "what": "開發 ChatGPT 和 GPT 系列的 AI 公司",
        "biz": "OpenAI 的技術和定價策略影響企業 AI 導入的成本效益",
    },
    "microsoft": {
        "what": "全球最大軟體公司之一，擁有 Windows、Office、Azure 雲端",
        "biz": "Microsoft 生態系是多數企業 IT 基礎設施的核心",
    },
    "google": {
        "what": "全球最大搜尋引擎和廣告平台，也是主要雲端供應商",
        "biz": "Google 的政策變動影響 SEO、廣告投放和雲端成本",
    },
    "aws": {
        "what": "Amazon Web Services，全球最大的雲端運算平台",
        "biz": "AWS 是多數企業雲端基礎設施首選，定價影響 IT 預算",
    },
    "sec": {
        "what": "美國證券交易委員會，監管股票市場和上市公司",
        "biz": "SEC 的監管動作影響上市/融資策略和合規成本",
    },
    "ipo": {
        "what": "首次公開發行股票，公司從私有轉為公開上市",
        "biz": "IPO 影響募資策略、估值預期和競爭對手動向",
    },
    "antitrust": {
        "what": "反壟斷法規，防止企業過度壟斷市場的法律",
        "biz": "反壟斷調查可能阻止併購案或迫使企業拆分業務",
    },
    "bandwidth": {
        "what": "網路一次能傳輸多少資料的上限，像是水管的粗細",
        "biz": "頻寬不足會影響雲端服務品質和遠端辦公體驗",
    },
    "latency": {
        "what": "從發出請求到收到回應的等待時間",
        "biz": "高延遲影響用戶體驗和即時交易系統的可靠性",
    },
    "encryption": {
        "what": "把資料轉換成只有授權者才能讀取的密碼形式",
        "biz": "加密是資料保護的基礎，法規常要求傳輸和儲存都要加密",
    },
    "vpn": {
        "what": "虛擬私人網路，在公共網路上建立加密的私人通道",
        "biz": "VPN 是遠端辦公的安全基礎設施，但也可能被用來繞過管制",
    },
    "cdn": {
        "what": "內容分發網路，把網站內容複製到全球各地的伺服器加速存取",
        "biz": "CDN 影響網站速度和全球用戶體驗，是數位業務的基礎設施",
    },
    "machine learning": {
        "what": "讓電腦從資料中自動學習規律和做預測的技術",
        "biz": "ML 可應用於推薦系統、風控、預測分析，但需要高品質資料",
    },
    "deep learning": {
        "what": "機器學習的進階版，用多層神經網路處理複雜模式",
        "biz": "深度學習驅動圖像辨識、語音助理等產品，但訓練成本高",
    },
    "autonomous driving": {
        "what": "自動駕駛，讓車輛不需人類操控就能行駛的技術",
        "biz": "自駕技術影響物流成本、保險模式和法規合規需求",
    },
    "sustainability": {
        "what": "在滿足當前需求的同時，不損害未來世代滿足需求的能力",
        "biz": "ESG 和永續報告已成為投資人和監管機構的硬性要求",
    },
    # VC / Finance
    "venture capital": {
        "what": "創投，投資早期新創公司並換取股權的資金",
        "biz": "創投趨勢反映哪些領域被看好，影響競爭格局和人才流向",
    },
    "mega-round": {
        "what": "超大型融資輪，通常指單輪募資超過 1 億美元",
        "biz": "巨額融資意味著該領域競爭加劇，新進者門檻升高",
    },
    "silicon valley": {
        "what": "美國加州的科技產業聚集區，全球科技創新中心",
        "biz": "矽谷趨勢通常領先全球 6-12 個月，值得提前佈局",
    },
}


def extract_key_terms(card: EduNewsCard) -> list[str]:
    """Extract unique English technical terms from card fields.

    Strict rules:
    - Skip all words in _STOP_WORDS (very broad)
    - Only keep words that are likely technical: capitalized, contain digits/hyphens,
      or match a known term in TERM_DICTIONARY
    - Max 5 terms
    """
    sources = [
        card.title_plain or "",
        card.what_happened or "",
        card.technical_interpretation or "",
    ]
    for line in (card.evidence_lines or []):
        sources.append(line)
    for line in (card.fact_check_confirmed or []):
        sources.append(line)
    for line in (card.derivable_effects or []):
        sources.append(line)

    combined = " ".join(sources)
    raw_terms = _TERM_RE.findall(combined)

    seen: set[str] = set()
    unique: list[str] = []
    for t in raw_terms:
        low = t.lower()
        if low in _STOP_WORDS or low in seen or len(t) < 3:
            continue
        # Only keep if it looks like a real term:
        # 1) In our curated dictionary
        # 2) Contains a digit or hyphen (e.g. "x86-64", "5G")
        # 3) Is a proper noun (starts with uppercase, length >= 4)
        # 4) Matches a known TERM_METAPHOR
        is_in_dict = _lookup_term(t) is not None
        has_special = bool(re.search(r"[\d-]", t))
        is_proper = t[0].isupper() and len(t) >= 4
        if not (is_in_dict or has_special or is_proper):
            continue
        seen.add(low)
        unique.append(t)

    return unique[:5]


# Keep old name as alias for backward compatibility in tests
_extract_english_terms = extract_key_terms


# ---------------------------------------------------------------------------
# Context-aware term explainer with curated dictionary
# ---------------------------------------------------------------------------

from schemas.education_models import TERM_METAPHORS as _CURATED_TERMS


def _lookup_term(term: str) -> dict[str, str] | None:
    """Look up a term in the curated dictionary (case-insensitive).

    Matching rules (prevents false positives like "ar" matching "department"):
    - Exact match: always accepted.
    - Multi-word keys ("deep learning"): only match if the query term
      exactly matches one of the key's component words.
    - Single-word keys: substring match only if both sides >= 4 chars
      AND the shorter side is >= 70% of the longer side.
    """
    low = term.lower()
    # Exact match
    if low in TERM_DICTIONARY:
        return TERM_DICTIONARY[low]
    for key, val in TERM_DICTIONARY.items():
        if " " in key:
            # Multi-word key: query must match one of the words exactly
            if low in key.split():
                return val
        else:
            # Single-word key: tight substring match
            shorter = min(len(low), len(key))
            longer = max(len(low), len(key))
            if shorter >= 4 and shorter >= longer * 0.7:
                if low in key or key in low:
                    return val
    return None


def build_term_explainer(card: EduNewsCard) -> list[dict[str, str]]:
    """Build context-aware term explanations for CEO audience.

    Returns list of dicts: [{"term": ..., "explain": ...}, ...]
    Uses curated dictionary first, then TERM_METAPHORS, then gap indicator.
    Never produces "與...相關的技術或概念" template.
    """
    terms = extract_key_terms(card)
    if not terms:
        return []

    results: list[dict[str, str]] = []
    for term in terms[:3]:  # max 3 per spec
        low = term.lower()

        # 1) Check our curated CEO dictionary first
        curated_dict = _lookup_term(term)
        if curated_dict:
            what_line = curated_dict["what"]
            biz_line = curated_dict["biz"]
            results.append({
                "term": term,
                "explain": what_line,
                "biz": f"CEO 在意：{biz_line}",
            })
            continue

        # 2) Check education TERM_METAPHORS (exact or near-exact only)
        metaphor = None
        for key, val in _CURATED_TERMS.items():
            key_low = key.lower()
            if low == key_low:
                metaphor = val
                break
            # Substring match only if >= 4 chars
            if len(low) >= 4 and low in key_low:
                metaphor = val
                break
            if len(key_low) >= 4 and key_low in low:
                metaphor = val
                break
        if metaphor:
            results.append({"term": term, "explain": metaphor, "biz": ""})
            continue

        # 3) Gap indicator — never produce empty-talk template
        results.append({
            "term": term,
            "explain": "目前資料缺口：無法在來源中確認此名詞的具體指涉",
            "biz": "",
        })

    return results


def build_term_explainer_lines(card: EduNewsCard) -> list[str]:
    """Flat-line version of build_term_explainer for Notion-style output.

    Format per term:
      名詞：一句話是什麼
      CEO 在意：一句話（成本/風險/競爭/合規）
    """
    items = build_term_explainer(card)
    lines: list[str] = []
    for item in items:
        lines.append(f"{item['term']}：{item['explain']}")
        if item.get("biz"):
            lines.append(f"  {item['biz']}")
        lines.append("")
    return lines


# Keep old function name as alias so existing imports don't break
def build_term_explainer_qa(card: EduNewsCard) -> list[str]:
    """Backward-compatible alias — returns flat lines."""
    return build_term_explainer_lines(card)


# ---------------------------------------------------------------------------
# Executive Summary — daily business narrative (3–5 sentences)
# ---------------------------------------------------------------------------

SUMMARY_TONE_LIBRARY: dict[str, dict[str, list[str]]] = {
    "neutral": {
        "risk_words": ["可能帶來風險", "需要持續觀察"],
        "action_words": ["建議持續關注", "建議評估影響"],
    },
    "conservative": {
        "risk_words": ["需審慎評估", "潛在不確定性升高"],
        "action_words": ["建議暫緩", "建議保守應對"],
    },
    "aggressive": {
        "risk_words": ["競爭壓力上升", "市場窗口正在形成"],
        "action_words": ["應積極布局", "建議加速投入"],
    },
    "risk": {
        "risk_words": ["風險正在累積", "需立即關注"],
        "action_words": ["建議啟動應對", "需要快速決策"],
    },
}


def build_executive_summary(
    news_cards: list[EduNewsCard],
    tone: str = "neutral",
) -> list[str]:
    """Synthesize multiple news cards into a 3–5 sentence business narrative.

    This is NOT a bullet list — it reads like a daily CEO briefing paragraph.
    Sources: each card's why_it_matters, possible_impact, risks.

    Args:
        news_cards: list of EduNewsCard to summarize.
        tone: one of "neutral", "conservative", "aggressive", "risk".

    Returns list of 3–5 complete Chinese sentences (no bullets).
    """
    tone_dict = SUMMARY_TONE_LIBRARY.get(tone, SUMMARY_TONE_LIBRARY["neutral"])
    risk_word = tone_dict["risk_words"][0]
    action_word = tone_dict["action_words"][0]

    event_cards = [
        c for c in news_cards
        if c.is_valid_news and not is_non_event_or_index(c)
    ]

    if not event_cards:
        return [
            "今日掃描的資訊來源中，沒有需要管理層立即關注的重大事件。",
            "多數內容為產業索引頁或非單一事件報導，已自動排除。",
            f"{action_word}目前監控頻率，明日再檢視是否有新動態浮現。",
        ]

    # Collect raw material from all event cards
    categories: list[str] = []
    why_fragments: list[str] = []
    impact_fragments: list[str] = []
    risk_fragments: list[str] = []

    for card in event_cards:
        article = build_ceo_article_blocks(card)

        cat = (card.category or "").strip()
        if cat and cat not in categories:
            categories.append(cat)

        for w in article.get("why_it_matters", []):
            cleaned = _clean_text(w, 80)
            if cleaned and len(cleaned) > 8 and not cleaned.startswith("缺口"):
                why_fragments.append(cleaned)

        for imp in article.get("possible_impact", []):
            cleaned = _clean_text(imp, 80)
            if cleaned and len(cleaned) > 8 and not cleaned.startswith("缺口"):
                impact_fragments.append(cleaned)

        for r in article.get("risks", []):
            cleaned = _clean_text(r, 80)
            if cleaned and len(cleaned) > 8 and not cleaned.startswith("缺口"):
                risk_fragments.append(cleaned)

    # Build narrative sentences
    n_events = len(event_cards)
    sentences: list[str] = []

    # Sentence 1: market overview (what happened today)
    cat_label = "、".join(categories[:3]) if categories else "科技"
    sentences.append(
        f"今日共有 {n_events} 則值得關注的市場動態，"
        f"主要集中在{cat_label}領域。"
    )

    # Sentence 2: why it matters (trend / competitive signal)
    if why_fragments:
        best_why = _smart_truncate(why_fragments[0], 100)
        sentences.append(f"目前趨勢顯示：{best_why}。")
    elif impact_fragments:
        best_imp = _smart_truncate(impact_fragments[0], 100)
        sentences.append(f"對公司而言，{best_imp}。")

    # Sentence 3: broader impact
    if impact_fragments and len(sentences) < 4:
        used = set(sentences)
        for frag in impact_fragments:
            candidate = f"從競爭與成本面來看，{_smart_truncate(frag, 100)}。"
            if candidate not in used:
                sentences.append(candidate)
                break

    # Sentence 4: risk posture (tone-aware)
    if risk_fragments:
        best_risk = _smart_truncate(risk_fragments[0], 100)
        sentences.append(f"風險方面，{risk_word}：{best_risk}。")
    else:
        sentences.append(f"目前沒有需要立即決策的高風險事項，但{risk_word}。")

    # Sentence 5: recommendation (tone-aware)
    if n_events >= 3:
        sentences.append(
            f"{action_word}，管理層本週內安排簡短討論，確認是否需要調整策略方向。"
        )
    else:
        sentences.append(
            f"{action_word}相關發展，如有變化將在下次報告中更新。"
        )

    # Ensure 3–5 sentences
    return sentences[:5]


# ---------------------------------------------------------------------------
# CEO article blocks (replaces Q/A format with article-style content)
# ---------------------------------------------------------------------------


def build_ceo_article_blocks(card: EduNewsCard) -> dict[str, str | list[str]]:
    """Build article-style content blocks for CEO-readable output.

    Returns dict with keys:
        headline_cn: headline (≤40 chars, word-boundary truncated)
        one_liner: One-sentence summary of the event (≤80 chars)
        known_facts: list of 3 known facts
        why_it_matters: list of 2 business-language reasons
        possible_impact: list of 2-3 possible impacts
        risks: list of 2 risks
        what_to_do: list of 1-2 concrete actions
        quote: Key evidence quote from the source (≤120 chars)
        sources: list of source URLs
        owner: responsible party
    """
    dc = build_decision_card(card)

    # headline — word-boundary truncated
    raw_title = sanitize(card.title_plain or "事件摘要")
    headline = _smart_truncate(raw_title, 40)

    # one_liner — what happened, sentence-boundary truncated
    if card.what_happened:
        raw_one = sanitize(card.what_happened)
        one_liner = _smart_truncate(raw_one, 80) if raw_one else dc["event"]
    else:
        one_liner = dc["event"]

    # known_facts — from decision card
    known_facts = dc["facts"][:3]

    # why_it_matters — from why_important ONLY (not effects, to avoid duplication)
    why_parts: list[str] = []
    if card.why_important:
        cleaned = _clean_text(card.why_important, 120)
        if cleaned and len(cleaned) > 10:
            why_parts.append(cleaned)
    if not why_parts:
        # Fallback: use first non-gap effect
        for eff in dc["effects"]:
            if not eff.startswith("缺口"):
                why_parts.append(eff)
                break
    if not why_parts:
        why_parts.append("缺口：影響面待進一步分析（原始資料不足）")

    # possible_impact — from derivable_effects ONLY, no overlap with why_it_matters
    impacts: list[str] = []
    used_texts = set(why_parts)  # avoid duplicating why_it_matters content
    for eff in dc["effects"]:
        if not eff.startswith("缺口") and eff not in used_texts:
            impacts.append(eff)
    if not impacts:
        impacts.append("缺口：影響面尚待分析")

    # risks — separate from impacts, from speculative_effects only
    risks = dc["risks"][:2]

    # what_to_do — concrete action with owner; quality-check each item
    actions: list[str] = []
    for a in dc["actions"]:
        # Skip broken fragments (< 6 meaningful chars)
        if len(a) >= 6:
            actions.append(f"{a}（負責人：{dc['owner']}）")
    if not actions:
        actions.append(f"決策者需要確認：此事件是否影響現有業務（負責人：{dc['owner']}）")

    # quote — best evidence line, sentence-boundary truncated
    quote = ""
    for line in (card.evidence_lines or []):
        cleaned = sanitize(line)
        if cleaned and len(cleaned) > 15:
            quote = _smart_truncate(cleaned, 120)
            break
    if not quote:
        for line in (card.fact_check_confirmed or []):
            cleaned = sanitize(line)
            if cleaned and len(cleaned) > 10:
                quote = _smart_truncate(cleaned, 120)
                break

    # sources
    sources: list[str] = []
    if card.source_url and card.source_url.startswith("http"):
        sources.append(card.source_url)

    return {
        "headline_cn": headline,
        "one_liner": one_liner,
        "known_facts": known_facts,
        "why_it_matters": why_parts[:3],
        "possible_impact": impacts[:3],
        "risks": risks,
        "what_to_do": actions[:2],
        "quote": quote,
        "sources": sources,
        "owner": dc["owner"],
    }


def build_executive_qa(card: EduNewsCard, dc: dict) -> list[str]:
    """Build 總經理決策 QA lines, referencing actual card data (not templates)."""
    short_title = _smart_truncate(sanitize(card.title_plain or ""), 20)
    fact_ref = dc["facts"][0] if dc["facts"] else "資料不足"
    effect_ref = dc["effects"][0] if dc["effects"] else "待評估"
    risk_ref = dc["risks"][0] if dc["risks"] else "低"
    action_ref = dc["actions"][0] if dc["actions"] else "待確認"
    owner = dc["owner"]

    lines = [
        f"Q1：「{short_title}」影響收入/成本/合規/交付節奏？",
        f"→ {effect_ref}。風險為「{risk_ref}」。",
        "",
        f"Q2：今天要拍板嗎？延後 2 週代價？",
        f"→ {action_ref}。建議由{owner}於本週內回覆評估結論。",
        "",
        f"Q3：最小試探動作（<=1週 <=1 owner）？",
        f"→ 指派{owner}用 1 個工作天完成初步影響評估並回報。",
    ]
    return lines


# ---------------------------------------------------------------------------
# CEO Brief — new functions for CEO Decision Brief upgrade
# ---------------------------------------------------------------------------

# Regex to extract numbers with optional units from text
_NUMBER_RE = re.compile(
    r"(\d[\d,.]*)\s*(%|億|萬|百萬|千萬|million|billion|percent|"
    r"美元|元|USD|users|用戶|人|家|間|台|款|項|個|筆|件)",
    re.IGNORECASE,
)


def build_data_card(card: EduNewsCard) -> list[dict[str, str]]:
    """Extract numeric metrics from card text via regex.

    Returns list of 1–3 dicts: [{"label": ..., "value": ...}, ...]
    Sources: what_happened, fact_check_confirmed, evidence_lines, derivable_effects.
    """
    sources = [card.what_happened or ""]
    sources.extend(card.fact_check_confirmed or [])
    sources.extend(card.evidence_lines or [])
    sources.extend(card.derivable_effects or [])
    combined = " ".join(sources)

    metrics: list[dict[str, str]] = []
    seen_values: set[str] = set()
    for match in _NUMBER_RE.finditer(combined):
        value = match.group(1)
        unit = match.group(2)
        if value in seen_values:
            continue
        seen_values.add(value)
        # Extract surrounding context as label (up to 15 chars before match)
        start = max(0, match.start() - 15)
        prefix = combined[start:match.start()].strip()
        # Clean prefix to a short label
        label = re.sub(r"^.*[，。；：,;:\s]", "", prefix)
        if not label:
            label = "數據"
        metrics.append({"label": label, "value": f"{value}{unit}"})
        if len(metrics) >= 3:
            break

    # Ensure at least 1 metric
    if not metrics:
        score = card.final_score
        metrics.append({"label": "重要性評分", "value": f"{score:.1f}/10"})

    return metrics


def build_chart_spec(card: EduNewsCard) -> dict:
    """Build a simple chart specification from card data.

    Returns dict: {"type": "bar"|"line"|"pie", "labels": [...], "values": [...]}
    """
    data_card = build_data_card(card)

    labels = [m["label"] for m in data_card]
    # Extract numeric part from value strings
    values: list[float] = []
    for m in data_card:
        nums = re.findall(r"[\d,.]+", m["value"])
        if nums:
            try:
                values.append(float(nums[0].replace(",", "")))
            except ValueError:
                values.append(0.0)
        else:
            values.append(0.0)

    # Choose chart type based on data characteristics
    if len(labels) == 1:
        chart_type = "bar"
    elif len(labels) == 2:
        chart_type = "line"
    else:
        chart_type = "pie"

    return {
        "type": chart_type,
        "labels": labels,
        "values": values,
    }


def build_video_source(card: EduNewsCard) -> list[dict[str, str]]:
    """Convert video_suggestions to YouTube search URLs.

    Returns list of dicts: [{"title": ..., "url": ...}, ...]
    """
    results: list[dict[str, str]] = []
    suggestions = card.video_suggestions or []
    for sug in suggestions[:2]:
        cleaned = sanitize(sug)
        if not cleaned:
            continue
        # Strip common prefixes
        query = re.sub(r"^(YouTube\s*(search|搜尋)[：:]\s*)", "", cleaned, flags=re.IGNORECASE)
        query = query.strip()
        if not query:
            continue
        # URL-encode the query
        import urllib.parse
        encoded = urllib.parse.quote_plus(query)
        url = f"https://www.youtube.com/results?search_query={encoded}"
        results.append({"title": query, "url": url})

    # Fallback: generate from title
    if not results and card.title_plain:
        title = sanitize(card.title_plain)
        if title:
            import urllib.parse
            encoded = urllib.parse.quote_plus(title)
            url = f"https://www.youtube.com/results?search_query={encoded}"
            results.append({"title": title, "url": url})

    return results


# CEO metaphor connectors — at least one must appear
_METAPHOR_CONNECTORS = ["就像", "等於是", "可以想像成", "好比", "類似於"]


def build_ceo_metaphor(card: EduNewsCard) -> str:
    """Build a CEO-readable metaphor (2–3 sentences) with mandatory connector.

    Sources: card.metaphor, what_happened, why_important.
    Must contain at least one of: 就像、等於是、可以想像成、好比、類似於
    """
    raw = (card.metaphor or "").strip()
    raw_sanitized = sanitize(raw) if raw else ""

    # Check if raw metaphor already has a connector
    if raw_sanitized and any(c in raw_sanitized for c in _METAPHOR_CONNECTORS):
        return _smart_truncate(raw_sanitized, 120)

    # Build from scratch using card content
    what = _clean_text(card.what_happened or "", 40)
    why = _clean_text(card.why_important or "", 40)

    if raw_sanitized:
        # Add connector to existing metaphor
        result = f"這件事就像{raw_sanitized}。"
        if why:
            result += f"對公司而言，等於是{why}。"
    elif what and why:
        result = f"可以想像成：{what}。等於是{why}。"
    elif what:
        result = f"可以想像成：{what}。"
    else:
        result = "就像產業地圖正在重新繪製，需要確認自己的位置是否改變。"

    return _smart_truncate(result, 150)


def build_ceo_brief_blocks(card: EduNewsCard) -> dict:
    """Core assembly function: build all CEO Brief blocks for one card.

    Returns dict with keys for Slide 1 (WHAT HAPPENED) and Slide 2 (WHY IT MATTERS):

    Slide 1 keys:
        title: str (≤14 chars)
        ai_trend_liner: str
        image_query: str
        event_liner: str
        data_card: list[dict]
        chart_spec: dict
        ceo_metaphor: str

    Slide 2 keys:
        q1_meaning: str (商業意義)
        q2_impact: str (對公司影響)
        q3_actions: list[str] (≤3 actions)
        video_source: list[dict]
        sources: list[str]
    """
    article = build_ceo_article_blocks(card)
    dc = build_decision_card(card)

    # --- Slide 1: WHAT HAPPENED ---
    raw_title = sanitize(card.title_plain or "事件摘要")
    title = _smart_truncate(raw_title, 14)

    # AI trend liner from category + why_important
    cat = card.category or "科技"
    why = _clean_text(card.why_important or "", 60)
    ai_trend_liner = f"【{cat}趨勢】{why}" if why else f"【{cat}趨勢】市場正在關注此領域的最新動態"

    # Image query for visual search
    image_query = f"{sanitize(card.title_plain or '')} {cat} AI technology"

    # Event liner
    event_liner = article["one_liner"]

    # Data card + chart spec
    data_card = build_data_card(card)
    chart_spec = build_chart_spec(card)

    # CEO metaphor
    ceo_metaphor = build_ceo_metaphor(card)

    # --- Slide 2: WHY IT MATTERS (Q&A) ---
    # Q1: 商業意義
    why_parts = article.get("why_it_matters", [])
    q1 = why_parts[0] if why_parts else "此事件的商業意義尚待進一步分析"

    # Q2: 對公司影響 (product/cost/opportunity/risk)
    impacts = article.get("possible_impact", [])
    risks = article.get("risks", [])
    impact_str = impacts[0] if impacts else "影響面待評估"
    risk_str = risks[0] if risks else "風險待評估"
    q2 = f"{impact_str}。風險面：{risk_str}"

    # Q3: 現在要做什麼 (≤3 actions)
    actions: list[str] = []
    for a in dc["actions"][:2]:
        cleaned = _clean_text(a, 50)
        if cleaned:
            actions.append(cleaned)
    if not actions:
        actions.append("確認此事件是否影響現有業務或專案排程")
    # Add owner action
    owner = dc["owner"]
    actions.append(f"指派{owner}於本週內回覆評估結論")
    actions = actions[:3]

    # Video source
    video_source = build_video_source(card)

    # Sources
    sources: list[str] = []
    if card.source_url and card.source_url.startswith("http"):
        sources.append(card.source_url)

    return {
        # Slide 1
        "title": title,
        "ai_trend_liner": ai_trend_liner,
        "image_query": image_query,
        "event_liner": event_liner,
        "data_card": data_card,
        "chart_spec": chart_spec,
        "ceo_metaphor": ceo_metaphor,
        # Slide 2
        "q1_meaning": q1,
        "q2_impact": q2,
        "q3_actions": actions,
        "video_source": video_source,
        "sources": sources,
    }


def build_structured_executive_summary(
    news_cards: list[EduNewsCard],
    tone: str = "neutral",
) -> dict[str, list[str]]:
    """Build a structured 5-section executive summary for CEO Decision Brief.

    Returns dict with 5 keys, each containing a list of bullet strings:
        ai_trends: AI 技術趨勢方向
        tech_landing: 正在落地的技術
        market_competition: 市場與競爭動態
        opportunities_risks: 機會與風險
        recommended_actions: 建議行動
    """
    tone_dict = SUMMARY_TONE_LIBRARY.get(tone, SUMMARY_TONE_LIBRARY["neutral"])
    risk_word = tone_dict["risk_words"][0]
    action_word = tone_dict["action_words"][0]

    event_cards = [
        c for c in news_cards
        if c.is_valid_news and not is_non_event_or_index(c)
    ]

    if not event_cards:
        return {
            "ai_trends": ["今日未發現需要關注的 AI 技術新趨勢。"],
            "tech_landing": ["今日無新技術落地動態。"],
            "market_competition": ["市場面暫無重大變化。"],
            "opportunities_risks": [f"目前沒有立即的風險事項，但{risk_word}。"],
            "recommended_actions": [f"{action_word}目前監控頻率。"],
        }

    ai_trends: list[str] = []
    tech_landing: list[str] = []
    market_competition: list[str] = []
    opportunities_risks: list[str] = []
    recommended_actions: list[str] = []

    for card in event_cards:
        article = build_ceo_article_blocks(card)
        cat = (card.category or "").lower()
        short_title = _smart_truncate(sanitize(card.title_plain or ""), 25)

        # Classify into sections based on category + content
        why = article.get("why_it_matters", [])
        why_text = why[0] if why else ""
        impacts = article.get("possible_impact", [])
        impact_text = impacts[0] if impacts else ""
        risks_list = article.get("risks", [])
        risk_text = risks_list[0] if risks_list else ""
        actions = article.get("what_to_do", [])
        action_text = actions[0] if actions else ""

        # AI trends: AI-related categories
        if any(kw in cat for kw in ["ai", "人工", "機器", "模型"]):
            if why_text and not why_text.startswith("缺口"):
                ai_trends.append(f"{short_title}：{_smart_truncate(why_text, 60)}")
            else:
                ai_trends.append(f"{short_title}：值得關注的 AI 領域動態")

        # Tech landing: tech/engineering categories
        if any(kw in cat for kw in ["tech", "科技", "工程", "雲", "資安"]):
            if impact_text and not impact_text.startswith("缺口"):
                tech_landing.append(f"{short_title}：{_smart_truncate(impact_text, 60)}")

        # Market competition: market/finance categories
        if any(kw in cat for kw in ["市場", "金融", "投融", "併購", "創業"]):
            if impact_text and not impact_text.startswith("缺口"):
                market_competition.append(f"{short_title}：{_smart_truncate(impact_text, 60)}")

        # Risks from all cards
        if risk_text and not risk_text.startswith("缺口"):
            opportunities_risks.append(f"{short_title}：{_smart_truncate(risk_text, 60)}")

        # Actions from all cards
        if action_text and not action_text.startswith("缺口"):
            recommended_actions.append(_smart_truncate(action_text, 70))

    # Ensure each section has at least one item
    if not ai_trends:
        # Fall back: use first event card
        c = event_cards[0]
        ai_trends.append(
            f"{_smart_truncate(sanitize(c.title_plain or ''), 25)}："
            f"可能影響 AI 產業格局"
        )
    if not tech_landing:
        tech_landing.append("本日事件中尚未出現明確的技術落地案例。")
    if not market_competition:
        market_competition.append("市場競爭面暫無重大訊號。")
    if not opportunities_risks:
        opportunities_risks.append(f"目前{risk_word}，需持續追蹤。")
    if not recommended_actions:
        recommended_actions.append(f"{action_word}相關發展，如有變化將即時更新。")

    # Cap each section at 3 items
    return {
        "ai_trends": ai_trends[:3],
        "tech_landing": tech_landing[:3],
        "market_competition": market_competition[:3],
        "opportunities_risks": opportunities_risks[:3],
        "recommended_actions": recommended_actions[:3],
    }


# ---------------------------------------------------------------------------
# v5 — Corp Watch company tiers
# ---------------------------------------------------------------------------

CORP_TIER_A = [
    "OpenAI", "Google", "Microsoft", "AWS", "Meta", "NVIDIA", "Apple",
]
CORP_TIER_B = [
    "阿里", "字節", "騰訊", "百度", "華為", "Alibaba", "ByteDance",
    "Tencent", "Baidu", "Huawei",
]
_ALL_CORPS = CORP_TIER_A + CORP_TIER_B

# Signal type keywords (derived from card content)
_SIGNAL_KEYWORDS = {
    "TOOL_ADOPTION": [
        "推出", "發布", "launch", "release", "開源", "open-source",
        "SDK", "API", "工具", "tool", "platform", "平台",
    ],
    "USER_PAIN": [
        "漏洞", "vulnerability", "資安", "安全", "breach", "hack",
        "隱私", "privacy", "風險", "risk", "裁員", "layoff",
        "關閉", "shutdown", "下架", "removed",
    ],
    "WORKFLOW_CHANGE": [
        "收購", "acqui", "併購", "merg", "投資", "invest", "合作",
        "partner", "整合", "integrat", "遷移", "migrat", "轉型",
        "transform", "取代", "replac",
    ],
}


# ---------------------------------------------------------------------------
# v5 — Market Heat Index
# ---------------------------------------------------------------------------


def compute_market_heat(cards: list[EduNewsCard]) -> dict:
    """Compute a 0-100 market heat index from card scores and volume.

    Returns dict:
        score: int (0-100)
        level: str ("LOW" / "MEDIUM" / "HIGH" / "VERY_HIGH")
        trend_word: str (Chinese description)
    """
    event_cards = [
        c for c in cards
        if c.is_valid_news and not is_non_event_or_index(c)
    ]
    if not event_cards:
        return {"score": 0, "level": "LOW", "trend_word": "市場平靜"}

    # Base score: average final_score mapped to 0-100
    avg_score = sum(c.final_score for c in event_cards) / len(event_cards)
    base = min(avg_score * 10, 80)  # max 80 from avg score

    # Volume bonus: more events = hotter market (up to +20)
    volume_bonus = min(len(event_cards) * 4, 20)

    raw = int(base + volume_bonus)
    score = max(0, min(100, raw))

    if score >= 75:
        return {"score": score, "level": "VERY_HIGH", "trend_word": "市場極度活躍"}
    elif score >= 50:
        return {"score": score, "level": "HIGH", "trend_word": "市場活躍"}
    elif score >= 25:
        return {"score": score, "level": "MEDIUM", "trend_word": "市場溫和波動"}
    else:
        return {"score": score, "level": "LOW", "trend_word": "市場平靜"}


# ---------------------------------------------------------------------------
# v5 — Event Impact Score (1-5)
# ---------------------------------------------------------------------------


def score_event_impact(card: EduNewsCard) -> dict:
    """Score an event 1-5 based on final_score + content richness.

    Returns dict:
        impact: int (1-5)
        label: str (e.g. "HIGH")
        color_tag: str ("red" / "orange" / "yellow" / "gray")
    """
    base = card.final_score or 0

    # Content richness bonus
    richness = 0
    if card.fact_check_confirmed:
        richness += len(card.fact_check_confirmed)
    if card.derivable_effects:
        richness += len(card.derivable_effects)
    if card.action_items:
        richness += len(card.action_items)

    # Map to 1-5
    raw = (base / 2.0) + min(richness * 0.3, 1.5)
    impact = max(1, min(5, round(raw)))

    labels = {5: "CRITICAL", 4: "HIGH", 3: "MEDIUM", 2: "LOW", 1: "MINIMAL"}
    colors = {5: "red", 4: "orange", 3: "yellow", 2: "gray", 1: "gray"}
    return {
        "impact": impact,
        "label": labels[impact],
        "color_tag": colors[impact],
    }


# ---------------------------------------------------------------------------
# v5 — CEO Action Engine (WATCH / TEST / MOVE)
# ---------------------------------------------------------------------------

_ACTION_MOVE_KEYWORDS = re.compile(
    r"立即|緊急|urgent|immediately|ASAP|now|馬上|必須|critical|高風險",
    re.IGNORECASE,
)
_ACTION_TEST_KEYWORDS = re.compile(
    r"評估|測試|試用|pilot|POC|prototype|experiment|assess|explore|研究",
    re.IGNORECASE,
)


def build_ceo_actions(cards: list[EduNewsCard]) -> list[dict]:
    """Classify events into WATCH / TEST / MOVE actions for CEO.

    Returns list of dicts:
        action_type: "MOVE" / "TEST" / "WATCH"
        title: str (event title, ≤25 chars)
        detail: str (action description)
        owner: str
        color_tag: str ("red" / "yellow" / "gray")
    """
    event_cards = [
        c for c in cards
        if c.is_valid_news and not is_non_event_or_index(c)
    ]
    results: list[dict] = []

    for card in event_cards[:8]:
        dc = build_decision_card(card)
        impact = score_event_impact(card)
        combined = f"{card.what_happened or ''} {card.why_important or ''}"
        for a in (card.action_items or []):
            combined += f" {a}"

        # Classify action type
        if impact["impact"] >= 4 or _ACTION_MOVE_KEYWORDS.search(combined):
            action_type = "MOVE"
            color_tag = "red"
        elif impact["impact"] >= 3 or _ACTION_TEST_KEYWORDS.search(combined):
            action_type = "TEST"
            color_tag = "yellow"
        else:
            action_type = "WATCH"
            color_tag = "gray"

        action_detail = dc["actions"][0] if dc["actions"] else "持續監控此事件發展"
        results.append({
            "action_type": action_type,
            "title": _smart_truncate(sanitize(card.title_plain or ""), 25),
            "detail": _clean_text(action_detail, 60),
            "owner": dc["owner"],
            "color_tag": color_tag,
        })

    # Sort: MOVE first, then TEST, then WATCH
    order = {"MOVE": 0, "TEST": 1, "WATCH": 2}
    results.sort(key=lambda x: order.get(x["action_type"], 3))
    return results


# ---------------------------------------------------------------------------
# v5 — Signal Summary (derive signal types from card content)
# ---------------------------------------------------------------------------


def build_signal_summary(cards: list[EduNewsCard]) -> list[dict]:
    """Derive market signals from card content, classify by signal type.

    Returns list of dicts:
        signal_type: "TOOL_ADOPTION" / "USER_PAIN" / "WORKFLOW_CHANGE"
        title: str
        source_count: int (how many cards match)
        heat: str ("hot" / "warm" / "cool")
    """
    event_cards = [
        c for c in cards
        if c.is_valid_news and not is_non_event_or_index(c)
    ]
    type_buckets: dict[str, list[EduNewsCard]] = {
        "TOOL_ADOPTION": [],
        "USER_PAIN": [],
        "WORKFLOW_CHANGE": [],
    }

    for card in event_cards:
        combined = (
            f"{card.title_plain or ''} {card.what_happened or ''} "
            f"{card.why_important or ''}"
        ).lower()

        best_type = "TOOL_ADOPTION"  # default
        best_hits = 0
        for sig_type, keywords in _SIGNAL_KEYWORDS.items():
            hits = sum(1 for kw in keywords if kw.lower() in combined)
            if hits > best_hits:
                best_hits = hits
                best_type = sig_type
        type_buckets[best_type].append(card)

    results: list[dict] = []
    type_labels = {
        "TOOL_ADOPTION": "工具/產品發布",
        "USER_PAIN": "風險/痛點訊號",
        "WORKFLOW_CHANGE": "工作流程變革",
    }

    for sig_type, bucket_cards in type_buckets.items():
        if not bucket_cards:
            continue
        avg_score = sum(c.final_score for c in bucket_cards) / len(bucket_cards)
        if avg_score >= 7:
            heat = "hot"
        elif avg_score >= 5:
            heat = "warm"
        else:
            heat = "cool"

        heat_score = 90 if heat == "hot" else 65 if heat == "warm" else 40
        signal_text = _smart_truncate(sanitize(bucket_cards[0].title_plain or ""), 30)
        platform_count = len(bucket_cards)
        results.append({
            "signal_type": sig_type,
            "label": type_labels[sig_type],
            "title": signal_text,
            "source_count": platform_count,
            "heat": heat,
            "signal_text": signal_text,
            "platform_count": platform_count,
            "heat_score": heat_score,
        })

    # Sort by source_count descending
    results.sort(key=lambda x: x["source_count"], reverse=True)

    # v5.1: no-event fallback must return Top 3
    if not results:
        fallback_signals = [
            ("NO_EVENT", "Event Coverage", "No event candidates from scanned content", 0, 35),
            ("SOURCE_HEALTH", "Source Health", "Source ingestion completed with fallback coverage", 0, 45),
            ("WATCHLIST", "Watchlist", "Monitor upstream feeds for next actionable event", 0, 40),
        ]
        for sig_type, label, signal_text, platform_count, heat_score in fallback_signals:
            results.append(
                {
                    "signal_type": sig_type,
                    "label": label,
                    "title": signal_text,
                    "source_count": platform_count,
                    "heat": "cool",
                    "signal_text": signal_text,
                    "platform_count": platform_count,
                    "heat_score": heat_score,
                }
            )
        return results

    # Always return at least one signal
    if not results:
        results.append({
            "signal_type": "TOOL_ADOPTION",
            "label": "工具/產品發布",
            "title": "今日無明顯訊號",
            "source_count": 0,
            "heat": "cool",
        })

    return results


# ---------------------------------------------------------------------------
# v5 — Corp Watch (big tech monitoring)
# ---------------------------------------------------------------------------


def build_corp_watch_summary(cards: list[EduNewsCard]) -> dict:
    """Scan cards for mentions of major tech companies (Tier A + Tier B).

    Returns dict:
        tier_a: list[dict] — [{name, event_title, impact_label, action}]
        tier_b: list[dict] — [{name, event_title, impact_label, action}]
        total_mentions: int
    """
    tier_a_results: list[dict] = []
    tier_b_results: list[dict] = []

    event_cards = [
        c for c in cards
        if c.is_valid_news and not is_non_event_or_index(c)
    ]

    seen_corps: set[str] = set()

    for card in event_cards:
        combined = f"{card.title_plain or ''} {card.what_happened or ''}"

        for corp in CORP_TIER_A:
            if corp.lower() in combined.lower() and corp not in seen_corps:
                seen_corps.add(corp)
                impact = score_event_impact(card)
                dc = build_decision_card(card)
                tier_a_results.append({
                    "name": corp,
                    "event_title": _smart_truncate(
                        sanitize(card.title_plain or ""), 30
                    ),
                    "impact_label": impact["label"],
                    "action": dc["actions"][0] if dc["actions"] else "持續監控",
                })

        for corp in CORP_TIER_B:
            if corp.lower() in combined.lower() and corp not in seen_corps:
                seen_corps.add(corp)
                impact = score_event_impact(card)
                dc = build_decision_card(card)
                tier_b_results.append({
                    "name": corp,
                    "event_title": _smart_truncate(
                        sanitize(card.title_plain or ""), 30
                    ),
                    "impact_label": impact["label"],
                    "action": dc["actions"][0] if dc["actions"] else "持續監控",
                })

    source_names = {
        str(getattr(c, "source_name", "") or "").strip()
        for c in cards
        if str(getattr(c, "source_name", "") or "").strip()
    }
    fail_counter: Counter[str] = Counter()
    for c in cards:
        if bool(getattr(c, "is_valid_news", False)):
            continue
        invalid_cause = str(getattr(c, "invalid_cause", "") or "")
        invalid_reason = str(getattr(c, "invalid_reason", "") or "")
        reason = sanitize((invalid_cause or invalid_reason or "unknown").strip())
        if reason:
            fail_counter[reason] += 1

    top_fail_reasons = [
        {"reason": reason, "count": count}
        for reason, count in fail_counter.most_common(3)
    ]
    total_mentions = len(tier_a_results) + len(tier_b_results)

    return {
        "tier_a": tier_a_results[:7],
        "tier_b": tier_b_results[:5],
        "total_mentions": total_mentions,
        "updates": total_mentions,
        "sources_total": len(source_names) if source_names else len(cards),
        "success_count": sum(1 for c in cards if bool(getattr(c, "is_valid_news", False))),
        "fail_count": sum(1 for c in cards if not bool(getattr(c, "is_valid_news", False))),
        "top_fail_reasons": top_fail_reasons,
    }


# ---------------------------------------------------------------------------
# v5.2 overrides (minimal-intrusion patch layer)
# ---------------------------------------------------------------------------

# Corp watch target list update (v5.2)
CORP_TIER_A = [
    "OpenAI",
    "Google",
    "Microsoft",
    "Amazon",
    "Meta",
    "Apple",
    "NVIDIA",
]
CORP_TIER_B = [
    "Alibaba",
    "Tencent",
    "ByteDance",
    "Baidu",
    "Huawei",
]
_ALL_CORPS = CORP_TIER_A + CORP_TIER_B

_FALLBACK_SIGNAL_POOL = [
    "TOOL_ADOPTION",
    "USER_PAIN",
    "WORKFLOW_CHANGE",
    "COST_PRESSURE",
    "COMPETITION_SIGNAL",
]

_SIGNAL_LABELS = {
    "TOOL_ADOPTION": "Tool Adoption",
    "USER_PAIN": "User Pain",
    "WORKFLOW_CHANGE": "Workflow Change",
    "COST_PRESSURE": "Cost Pressure",
    "COMPETITION_SIGNAL": "Competition Signal",
}


def build_signal_summary(cards: list[EduNewsCard]) -> list[dict]:
    """Derive market signals from card content.

    Always returns Top 3 entries. When real signals are insufficient,
    backfills from a deterministic fallback pool.
    """
    event_cards = [
        c for c in cards
        if c.is_valid_news and not is_non_event_or_index(c)
    ]

    type_buckets: dict[str, list[EduNewsCard]] = {
        "TOOL_ADOPTION": [],
        "USER_PAIN": [],
        "WORKFLOW_CHANGE": [],
    }

    for card in event_cards:
        combined = (
            f"{card.title_plain or ''} {card.what_happened or ''} "
            f"{card.why_important or ''}"
        ).lower()

        best_type = "TOOL_ADOPTION"
        best_hits = 0
        for sig_type, keywords in _SIGNAL_KEYWORDS.items():
            hits = sum(1 for kw in keywords if kw.lower() in combined)
            if hits > best_hits:
                best_hits = hits
                best_type = sig_type
        type_buckets[best_type].append(card)

    results: list[dict] = []

    for sig_type, bucket_cards in type_buckets.items():
        if not bucket_cards:
            continue

        avg_score = sum(c.final_score for c in bucket_cards) / len(bucket_cards)
        heat_score = int(max(0, min(100, round(avg_score * 12))))
        if heat_score >= 75:
            heat = "hot"
        elif heat_score >= 50:
            heat = "warm"
        else:
            heat = "cool"

        signal_text = _smart_truncate(sanitize(bucket_cards[0].title_plain or ""), 30)
        source_names = {
            str(getattr(c, "source_name", "") or "").strip().lower()
            for c in bucket_cards
            if str(getattr(c, "source_name", "") or "").strip()
        }
        platform_count = len(source_names) if source_names else len(bucket_cards)

        first_snippet = bucket_cards[0].what_happened or bucket_cards[0].title_plain or ""
        example_snippet = _smart_truncate(sanitize(first_snippet), 120)

        results.append({
            "signal_name": sig_type,
            "signal_type": sig_type,
            "label": _SIGNAL_LABELS.get(sig_type, sig_type),
            "title": signal_text,
            "source_count": platform_count,
            "heat": heat,
            "signal_text": signal_text,
            "platform_count": platform_count,
            "heat_score": heat_score,
            "example_snippet": example_snippet,
        })

    results.sort(
        key=lambda x: (
            int(x.get("platform_count", 0)),
            int(x.get("heat_score", 0)),
        ),
        reverse=True,
    )

    used_names = {str(r.get("signal_name", "")) for r in results}
    fallback_scores = {
        "TOOL_ADOPTION": 60,
        "USER_PAIN": 58,
        "WORKFLOW_CHANGE": 55,
        "COST_PRESSURE": 50,
        "COMPETITION_SIGNAL": 48,
    }

    for fallback_name in _FALLBACK_SIGNAL_POOL:
        if len(results) >= 3:
            break
        if fallback_name in used_names:
            continue

        fallback_score = int(fallback_scores.get(fallback_name, 50))
        fallback_heat = "warm" if fallback_score >= 50 else "cool"
        fallback_text = _smart_truncate(
            sanitize(f"Monitoring signal: {fallback_name}"),
            30,
        )
        fallback_snippet = _smart_truncate(
            sanitize(f"Monitoring {fallback_name} due to limited event evidence."),
            120,
        )
        results.append({
            "signal_name": fallback_name,
            "signal_type": fallback_name,
            "label": _SIGNAL_LABELS.get(fallback_name, fallback_name),
            "title": fallback_text,
            "source_count": 0,
            "heat": fallback_heat,
            "signal_text": fallback_text,
            "platform_count": 0,
            "heat_score": fallback_score,
            "example_snippet": fallback_snippet,
        })

    return results[:3]


def build_corp_watch_summary(
    cards: list[EduNewsCard],
    metrics: dict | None = None,
) -> dict:
    """Scan cards for mentions of major tech companies (Tier A + Tier B)."""
    tier_a_results: list[dict] = []
    tier_b_results: list[dict] = []

    event_cards = [
        c for c in cards
        if c.is_valid_news and not is_non_event_or_index(c)
    ]

    seen_corps: set[str] = set()
    impact_values: list[int] = []

    for card in event_cards:
        combined = f"{card.title_plain or ''} {card.what_happened or ''}"

        for corp in CORP_TIER_A:
            if corp.lower() in combined.lower() and corp not in seen_corps:
                seen_corps.add(corp)
                impact = score_event_impact(card)
                impact_values.append(int(impact["impact"]))
                dc = build_decision_card(card)
                tier_a_results.append({
                    "name": corp,
                    "event_title": _smart_truncate(
                        sanitize(card.title_plain or ""), 30
                    ),
                    "impact_label": impact["label"],
                    "action": dc["actions"][0] if dc["actions"] else "Monitor follow-up",
                })

        for corp in CORP_TIER_B:
            if corp.lower() in combined.lower() and corp not in seen_corps:
                seen_corps.add(corp)
                impact = score_event_impact(card)
                impact_values.append(int(impact["impact"]))
                dc = build_decision_card(card)
                tier_b_results.append({
                    "name": corp,
                    "event_title": _smart_truncate(
                        sanitize(card.title_plain or ""), 30
                    ),
                    "impact_label": impact["label"],
                    "action": dc["actions"][0] if dc["actions"] else "Monitor follow-up",
                })

    source_names = {
        str(getattr(c, "source_name", "") or "").strip()
        for c in cards
        if str(getattr(c, "source_name", "") or "").strip()
    }

    fail_counter: Counter[str] = Counter()
    for c in cards:
        if bool(getattr(c, "is_valid_news", False)):
            continue
        invalid_cause = str(getattr(c, "invalid_cause", "") or "")
        invalid_reason = str(getattr(c, "invalid_reason", "") or "")
        reason = sanitize((invalid_cause or invalid_reason or "unknown").strip())
        if reason:
            fail_counter[reason] += 1

    top_fail_reasons = [
        {"reason": reason, "count": count}
        for reason, count in fail_counter.most_common(3)
    ]

    metrics_dict = metrics or {}
    total_mentions = len(tier_a_results) + len(tier_b_results)
    mentions_count = total_mentions

    if impact_values:
        impact_score_avg = round(sum(impact_values) / len(impact_values), 2)
    else:
        impact_score_avg = 0.0

    if mentions_count == 0:
        trend_direction = "STABLE"
    elif impact_score_avg >= 3.8 or mentions_count >= 3:
        trend_direction = "UP"
    elif impact_score_avg <= 2.0:
        trend_direction = "DOWN"
    else:
        trend_direction = "STABLE"

    sources_total = int(
        metrics_dict.get(
            "sources_total",
            len(source_names) if source_names else len(cards),
        )
    )
    success_count = int(
        metrics_dict.get(
            "sources_success",
            sum(1 for c in cards if bool(getattr(c, "is_valid_news", False))),
        )
    )
    fail_count = int(
        metrics_dict.get(
            "sources_failed",
            sum(1 for c in cards if not bool(getattr(c, "is_valid_news", False))),
        )
    )

    status_message = (
        "No major updates detected — monitoring continues."
        if mentions_count == 0
        else f"{mentions_count} tracked companies with notable updates."
    )

    return {
        "tier_a": tier_a_results[:7],
        "tier_b": tier_b_results[:5],
        "total_mentions": total_mentions,
        "mentions_count": mentions_count,
        "impact_score_avg": impact_score_avg,
        "trend_direction": trend_direction,
        "status_message": status_message,
        "updates": total_mentions,
        "sources_total": sources_total,
        "success_count": success_count,
        "fail_count": fail_count,
        "top_fail_reasons": top_fail_reasons,
    }

# ---------------------------------------------------------------------------
# v5.2.1 overrides (append-only hotfix layer)
# ---------------------------------------------------------------------------

# Keep the monitored corp list explicit and complete.
CORP_TIER_A = [
    "OpenAI",
    "Google",
    "Microsoft",
    "Amazon",
    "Meta",
    "Apple",
    "NVIDIA",
]
CORP_TIER_B = [
    "Alibaba",
    "Tencent",
    "ByteDance",
    "Baidu",
    "Huawei",
]
_ALL_CORPS = CORP_TIER_A + CORP_TIER_B

_FALLBACK_SIGNAL_POOL = [
    "TOOL_ADOPTION",
    "USER_PAIN",
    "WORKFLOW_CHANGE",
    "COST_PRESSURE",
    "COMPETITION_SIGNAL",
]

_SIGNAL_LABELS = {
    "TOOL_ADOPTION": "Tool Adoption",
    "USER_PAIN": "User Pain",
    "WORKFLOW_CHANGE": "Workflow Change",
    "COST_PRESSURE": "Cost Pressure",
    "COMPETITION_SIGNAL": "Competition Signal",
}

_V521_EXTRA_SIGNAL_KEYWORDS = {
    "COST_PRESSURE": [
        "cost", "pricing", "margin", "budget", "token price", "spend", "expense",
    ],
    "COMPETITION_SIGNAL": [
        "rival", "competition", "race", "market share", "challenger", "benchmark",
    ],
}


def _v521_strip_signal_placeholders(text: str) -> str:
    cleaned = text or ""
    cleaned = re.sub(r"(?i)fallback monitoring signal", "", cleaned)
    cleaned = re.sub(r"(?i)last\s+\w+\s+was\.{3,}", "", cleaned)
    return cleaned.strip()


def _v521_resolve_signal_type(combined: str) -> str:
    best_type = "TOOL_ADOPTION"
    best_hits = 0

    for sig_type, keywords in _SIGNAL_KEYWORDS.items():
        hits = sum(1 for kw in keywords if kw.lower() in combined)
        if hits > best_hits:
            best_hits = hits
            best_type = sig_type

    for sig_type, keywords in _V521_EXTRA_SIGNAL_KEYWORDS.items():
        hits = sum(1 for kw in keywords if kw.lower() in combined)
        if hits > best_hits:
            best_hits = hits
            best_type = sig_type

    return best_type


def _v521_heat_from_avg_score(avg_score: float) -> tuple[str, int]:
    heat_score = int(max(30, min(100, round(avg_score * 12))))
    if heat_score >= 75:
        return "hot", heat_score
    if heat_score >= 50:
        return "warm", heat_score
    return "cool", heat_score


def _v521_build_signal_entry(signal_name: str, bucket_cards: list[EduNewsCard]) -> dict:
    source_names = {
        str(getattr(c, "source_name", "") or "").strip().lower()
        for c in bucket_cards
        if str(getattr(c, "source_name", "") or "").strip()
    }
    platform_count = len(source_names) if source_names else len(bucket_cards)
    platform_count = max(platform_count, 1)

    avg_score = (
        sum(float(getattr(c, "final_score", 0.0) or 0.0) for c in bucket_cards) / len(bucket_cards)
        if bucket_cards else 3.0
    )
    heat, heat_score = _v521_heat_from_avg_score(avg_score)

    first = bucket_cards[0] if bucket_cards else None
    signal_text_raw = (
        (first.title_plain if first else "")
        or (first.what_happened if first else "")
        or _SIGNAL_LABELS.get(signal_name, signal_name)
    )
    signal_text = _smart_truncate(
        sanitize(_v521_strip_signal_placeholders(signal_text_raw)),
        30,
    )
    if not signal_text:
        signal_text = _SIGNAL_LABELS.get(signal_name, signal_name)

    snippet_raw = (
        (first.what_happened if first else "")
        or (first.why_important if first else "")
        or signal_text
    )
    example_snippet = _smart_truncate(
        sanitize(_v521_strip_signal_placeholders(snippet_raw)),
        120,
    )
    if not example_snippet:
        example_snippet = _smart_truncate(
            f"Tracking {_SIGNAL_LABELS.get(signal_name, signal_name)} from validated sources.",
            120,
        )

    return {
        "signal_name": signal_name,
        "signal_type": signal_name,
        "label": _SIGNAL_LABELS.get(signal_name, signal_name),
        "title": signal_text,
        "source_count": platform_count,
        "heat": heat,
        "signal_text": signal_text,
        "platform_count": platform_count,
        "heat_score": heat_score,
        "example_snippet": example_snippet,
    }


def build_signal_summary(cards: list[EduNewsCard]) -> list[dict]:
    """Derive market signals from card content.

    Event path keeps prior behavior; no-event path always returns Top 3
    concrete signals with non-zero platform_count and usable snippets.
    """
    event_cards = [
        c for c in cards
        if c.is_valid_news and not is_non_event_or_index(c)
    ]

    if event_cards:
        type_buckets: dict[str, list[EduNewsCard]] = {
            "TOOL_ADOPTION": [],
            "USER_PAIN": [],
            "WORKFLOW_CHANGE": [],
        }
        for card in event_cards:
            combined = (
                f"{card.title_plain or ''} {card.what_happened or ''} "
                f"{card.why_important or ''}"
            ).lower()
            best_type = "TOOL_ADOPTION"
            best_hits = 0
            for sig_type in ("TOOL_ADOPTION", "USER_PAIN", "WORKFLOW_CHANGE"):
                keywords = _SIGNAL_KEYWORDS.get(sig_type, [])
                hits = sum(1 for kw in keywords if kw.lower() in combined)
                if hits > best_hits:
                    best_hits = hits
                    best_type = sig_type
            type_buckets[best_type].append(card)

        results = [
            _v521_build_signal_entry(sig_type, bucket_cards)
            for sig_type, bucket_cards in type_buckets.items()
            if bucket_cards
        ]
        results.sort(
            key=lambda x: (
                int(x.get("platform_count", 0)),
                int(x.get("heat_score", 0)),
            ),
            reverse=True,
        )
        return results

    valid_cards = [c for c in cards if c.is_valid_news]
    try:
        from config import settings as _settings

        min_keep_signals = int(getattr(_settings, "CONTENT_GATE_MIN_KEEP_SIGNALS", 9) or 9)
    except Exception:
        min_keep_signals = 9

    signal_source_cards = valid_cards[: max(1, min_keep_signals)]

    buckets: dict[str, list[EduNewsCard]] = {
        name: [] for name in _FALLBACK_SIGNAL_POOL
    }
    for card in signal_source_cards:
        combined = (
            f"{card.title_plain or ''} {card.what_happened or ''} "
            f"{card.why_important or ''}"
        ).lower()
        sig_type = _v521_resolve_signal_type(combined)
        if sig_type not in buckets:
            sig_type = "TOOL_ADOPTION"
        buckets[sig_type].append(card)

    results: list[dict] = []
    for sig_name, bucket_cards in buckets.items():
        if not bucket_cards:
            continue
        entry = _v521_build_signal_entry(sig_name, bucket_cards)
        entry["heat_score"] = max(int(entry.get("heat_score", 30)), 30)
        entry["platform_count"] = max(int(entry.get("platform_count", 1)), 1)
        entry["source_count"] = entry["platform_count"]
        results.append(entry)

    results.sort(
        key=lambda x: (
            int(x.get("platform_count", 0)),
            int(x.get("heat_score", 0)),
        ),
        reverse=True,
    )

    used_names = {str(r.get("signal_name", "")) for r in results}
    template_cards = signal_source_cards if signal_source_cards else valid_cards

    for idx, fallback_name in enumerate(_FALLBACK_SIGNAL_POOL):
        if len(results) >= 3:
            break
        if fallback_name in used_names:
            continue

        if template_cards:
            entry = _v521_build_signal_entry(
                fallback_name,
                [template_cards[idx % len(template_cards)]],
            )
            entry["heat_score"] = max(int(entry.get("heat_score", 30)), 30)
            entry["platform_count"] = max(int(entry.get("platform_count", 1)), 1)
            entry["source_count"] = entry["platform_count"]
            results.append(entry)
            continue

        fallback_score = max(30, 45 - idx * 3)
        fallback_heat = "warm" if fallback_score >= 50 else "cool"
        fallback_text = _SIGNAL_LABELS.get(fallback_name, fallback_name)
        results.append(
            {
                "signal_name": fallback_name,
                "signal_type": fallback_name,
                "label": fallback_text,
                "title": fallback_text,
                "source_count": 1,
                "heat": fallback_heat,
                "signal_text": fallback_text,
                "platform_count": 1,
                "heat_score": fallback_score,
                "example_snippet": _smart_truncate(
                    f"Monitoring {fallback_text} from source coverage baselines.",
                    120,
                ),
            }
        )

    return results[:3]


def build_corp_watch_summary(
    cards: list[EduNewsCard],
    metrics: dict | None = None,
) -> dict:
    """Scan cards for mentions of major tech companies (Tier A + Tier B)."""
    tier_a_results: list[dict] = []
    tier_b_results: list[dict] = []

    event_cards = [
        c for c in cards
        if c.is_valid_news and not is_non_event_or_index(c)
    ]

    seen_corps: set[str] = set()
    impact_values: list[int] = []

    for card in event_cards:
        combined = f"{card.title_plain or ''} {card.what_happened or ''}"

        for corp in CORP_TIER_A:
            if corp.lower() in combined.lower() and corp not in seen_corps:
                seen_corps.add(corp)
                impact = score_event_impact(card)
                impact_values.append(int(impact["impact"]))
                dc = build_decision_card(card)
                tier_a_results.append(
                    {
                        "name": corp,
                        "event_title": _smart_truncate(
                            sanitize(card.title_plain or ""),
                            30,
                        ),
                        "impact_label": impact["label"],
                        "action": dc["actions"][0] if dc["actions"] else "Monitor follow-up",
                    }
                )

        for corp in CORP_TIER_B:
            if corp.lower() in combined.lower() and corp not in seen_corps:
                seen_corps.add(corp)
                impact = score_event_impact(card)
                impact_values.append(int(impact["impact"]))
                dc = build_decision_card(card)
                tier_b_results.append(
                    {
                        "name": corp,
                        "event_title": _smart_truncate(
                            sanitize(card.title_plain or ""),
                            30,
                        ),
                        "impact_label": impact["label"],
                        "action": dc["actions"][0] if dc["actions"] else "Monitor follow-up",
                    }
                )

    source_names = {
        str(getattr(c, "source_name", "") or "").strip()
        for c in cards
        if str(getattr(c, "source_name", "") or "").strip()
    }

    fail_counter: Counter[str] = Counter()
    for c in cards:
        if bool(getattr(c, "is_valid_news", False)):
            continue
        invalid_cause = str(getattr(c, "invalid_cause", "") or "")
        invalid_reason = str(getattr(c, "invalid_reason", "") or "")
        reason = sanitize((invalid_cause or invalid_reason or "unknown").strip())
        if reason:
            fail_counter[reason] += 1

    top_fail_reasons = [
        {"reason": reason, "count": count}
        for reason, count in fail_counter.most_common(3)
    ]
    if not top_fail_reasons:
        top_fail_reasons = [{"reason": "none", "count": 0}]

    metrics_dict = metrics or {}
    total_mentions = len(tier_a_results) + len(tier_b_results)
    mentions_count = total_mentions

    if impact_values:
        impact_score_avg = round(sum(impact_values) / len(impact_values), 2)
    else:
        impact_score_avg = 0.0

    if mentions_count == 0:
        trend_direction = "STABLE"
    elif impact_score_avg >= 3.8 or mentions_count >= 3:
        trend_direction = "UP"
    elif impact_score_avg <= 2.0:
        trend_direction = "DOWN"
    else:
        trend_direction = "STABLE"

    sources_total = int(
        metrics_dict.get(
            "sources_total",
            len(source_names) if source_names else len(cards),
        )
    )
    success_count = int(
        metrics_dict.get(
            "sources_success",
            sum(1 for c in cards if bool(getattr(c, "is_valid_news", False))),
        )
    )
    fail_count = int(
        metrics_dict.get(
            "sources_failed",
            sum(1 for c in cards if not bool(getattr(c, "is_valid_news", False))),
        )
    )

    status_message = (
        "No major updates detected — monitoring continues."
        if mentions_count == 0
        else f"{mentions_count} tracked companies with notable updates."
    )

    return {
        "tier_a": tier_a_results[:7],
        "tier_b": tier_b_results[:5],
        "total_mentions": total_mentions,
        "mentions_count": mentions_count,
        "impact_score_avg": impact_score_avg,
        "trend_direction": trend_direction,
        "status_message": status_message,
        "updates": total_mentions,
        "sources_total": sources_total,
        "success_count": success_count,
        "fail_count": fail_count,
        "top_fail_reasons": top_fail_reasons,
    }
